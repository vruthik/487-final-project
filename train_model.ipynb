{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"train_model.ipynb","provenance":[],"collapsed_sections":[]},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"},"accelerator":"GPU","widgets":{"application/vnd.jupyter.widget-state+json":{"8ced2d7a699d44a5b85d76aee4928b15":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_98481ee5c9a040c18bd7854791d466bf","IPY_MODEL_e07c295cc1af468f8f81f4c388185c50","IPY_MODEL_0a5940163ae24c4f80499ceb84a576b3"],"layout":"IPY_MODEL_7b28bdb4d9644d2da5e56cf13f631d12"}},"98481ee5c9a040c18bd7854791d466bf":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_6392bf64751d4793a35aa1091ed27220","placeholder":"​","style":"IPY_MODEL_4396c764d64b4f95a10a61ecabe742b9","value":"Downloading: 100%"}},"e07c295cc1af468f8f81f4c388185c50":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_8dad15a4caaa40f69b7fddcf878febc5","max":213450,"min":0,"orientation":"horizontal","style":"IPY_MODEL_4d5a7d56ee5a4da8b5e17b465b0da251","value":213450}},"0a5940163ae24c4f80499ceb84a576b3":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_054a160162a744809f5d392f00baa9eb","placeholder":"​","style":"IPY_MODEL_42cc0c1c3b4449c2ba7cfa9ef12837a3","value":" 208k/208k [00:00&lt;00:00, 864kB/s]"}},"7b28bdb4d9644d2da5e56cf13f631d12":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"6392bf64751d4793a35aa1091ed27220":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"4396c764d64b4f95a10a61ecabe742b9":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"8dad15a4caaa40f69b7fddcf878febc5":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"4d5a7d56ee5a4da8b5e17b465b0da251":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"054a160162a744809f5d392f00baa9eb":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"42cc0c1c3b4449c2ba7cfa9ef12837a3":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"2ee4c9d79ed14932a61ef9ab43a7a7c8":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_6a696060459d4eecb7e2cbb9c5e333ca","IPY_MODEL_bf0bb65a42f54787b81aa50761b98795","IPY_MODEL_9c562cdd90be4ed28ce706f5afb184c3"],"layout":"IPY_MODEL_6f14feb53e154d67a68b3ed1fc7b63b9"}},"6a696060459d4eecb7e2cbb9c5e333ca":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_dfbab0ca2549498f97f762cdb1f52c50","placeholder":"​","style":"IPY_MODEL_667808f5ef7f4d4bbaa97cec63044955","value":"Downloading: 100%"}},"bf0bb65a42f54787b81aa50761b98795":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_08caf25f85e1404d805efcb9ed3e5efc","max":29,"min":0,"orientation":"horizontal","style":"IPY_MODEL_ec0f7d1a6e3e4a3785379f394848e23c","value":29}},"9c562cdd90be4ed28ce706f5afb184c3":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_2456e9405e7c40c8a5bf5f42f47ef82a","placeholder":"​","style":"IPY_MODEL_b2832c5b6dac4d66a52c5fb0e046aaf3","value":" 29.0/29.0 [00:00&lt;00:00, 1.16kB/s]"}},"6f14feb53e154d67a68b3ed1fc7b63b9":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"dfbab0ca2549498f97f762cdb1f52c50":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"667808f5ef7f4d4bbaa97cec63044955":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"08caf25f85e1404d805efcb9ed3e5efc":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"ec0f7d1a6e3e4a3785379f394848e23c":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"2456e9405e7c40c8a5bf5f42f47ef82a":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"b2832c5b6dac4d66a52c5fb0e046aaf3":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}}}}},"cells":[{"cell_type":"code","execution_count":1,"source":["from google.colab import drive\n","drive.mount('/content/drive')"],"outputs":[{"output_type":"stream","name":"stdout","text":["Mounted at /content/drive\n"]}],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"X4m98mxXcHhL","executionInfo":{"status":"ok","timestamp":1648563902737,"user_tz":240,"elapsed":15267,"user":{"displayName":"Vruthik Thakkar","userId":"03035406201152502707"}},"outputId":"e908ccca-2504-4a77-e100-a3ba8f338b7c"}},{"cell_type":"code","execution_count":2,"source":["import os\n","import sys\n","\n","# TODO: change this to the path to your homework folder\n","GOOGLE_DRIVE_PATH_AFTER_MYDRIVE = '487-final-project'\n","GOOGLE_DRIVE_PATH = os.path.join('drive', 'My Drive', GOOGLE_DRIVE_PATH_AFTER_MYDRIVE)\n","print(os.listdir(GOOGLE_DRIVE_PATH))\n","sys.path.append(GOOGLE_DRIVE_PATH)"],"outputs":[{"output_type":"stream","name":"stdout","text":["['checkpoint_7.pth', 'checkpoint_no_na.pth', 'nb.ipynb', '__pycache__', 'data', 'requirements.txt', 'preprocess.py', 'test.py', 'eval.py', 'README.md', 'naivebayes.py', 'scrape.py', 'checkpoint.pth', 'model.py', 'train_model.ipynb']\n"]}],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"Wo2kkaQzcWhU","executionInfo":{"status":"ok","timestamp":1648563902877,"user_tz":240,"elapsed":143,"user":{"displayName":"Vruthik Thakkar","userId":"03035406201152502707"}},"outputId":"16067afc-36d6-4240-f0f4-ebdf3372bb23"}},{"cell_type":"code","execution_count":3,"source":["!pip install transformers\n","from transformers import BertTokenizer\n","import torch\n","import numpy as np\n","import pandas as pd\n","from torch import nn\n","from transformers import BertModel\n","from torch.optim import Adam\n","from google.colab import files"],"outputs":[{"output_type":"stream","name":"stdout","text":["Collecting transformers\n","  Downloading transformers-4.17.0-py3-none-any.whl (3.8 MB)\n","\u001b[K     |████████████████████████████████| 3.8 MB 8.9 MB/s \n","\u001b[?25hCollecting huggingface-hub<1.0,>=0.1.0\n","  Downloading huggingface_hub-0.4.0-py3-none-any.whl (67 kB)\n","\u001b[K     |████████████████████████████████| 67 kB 5.3 MB/s \n","\u001b[?25hRequirement already satisfied: importlib-metadata in /usr/local/lib/python3.7/dist-packages (from transformers) (4.11.3)\n","Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.7/dist-packages (from transformers) (1.21.5)\n","Collecting tokenizers!=0.11.3,>=0.11.1\n","  Downloading tokenizers-0.11.6-cp37-cp37m-manylinux_2_12_x86_64.manylinux2010_x86_64.whl (6.5 MB)\n","\u001b[K     |████████████████████████████████| 6.5 MB 54.1 MB/s \n","\u001b[?25hRequirement already satisfied: filelock in /usr/local/lib/python3.7/dist-packages (from transformers) (3.6.0)\n","Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.7/dist-packages (from transformers) (4.63.0)\n","Requirement already satisfied: requests in /usr/local/lib/python3.7/dist-packages (from transformers) (2.23.0)\n","Collecting sacremoses\n","  Downloading sacremoses-0.0.49-py3-none-any.whl (895 kB)\n","\u001b[K     |████████████████████████████████| 895 kB 54.2 MB/s \n","\u001b[?25hRequirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.7/dist-packages (from transformers) (2019.12.20)\n","Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.7/dist-packages (from transformers) (21.3)\n","Collecting pyyaml>=5.1\n","  Downloading PyYAML-6.0-cp37-cp37m-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_12_x86_64.manylinux2010_x86_64.whl (596 kB)\n","\u001b[K     |████████████████████████████████| 596 kB 55.4 MB/s \n","\u001b[?25hRequirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.7/dist-packages (from huggingface-hub<1.0,>=0.1.0->transformers) (3.10.0.2)\n","Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from packaging>=20.0->transformers) (3.0.7)\n","Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata->transformers) (3.7.0)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (2021.10.8)\n","Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (2.10)\n","Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (1.24.3)\n","Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (3.0.4)\n","Requirement already satisfied: six in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers) (1.15.0)\n","Requirement already satisfied: joblib in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers) (1.1.0)\n","Requirement already satisfied: click in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers) (7.1.2)\n","Installing collected packages: pyyaml, tokenizers, sacremoses, huggingface-hub, transformers\n","  Attempting uninstall: pyyaml\n","    Found existing installation: PyYAML 3.13\n","    Uninstalling PyYAML-3.13:\n","      Successfully uninstalled PyYAML-3.13\n","Successfully installed huggingface-hub-0.4.0 pyyaml-6.0 sacremoses-0.0.49 tokenizers-0.11.6 transformers-4.17.0\n"]}],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"e-MkQ_PFbltj","executionInfo":{"status":"ok","timestamp":1648563918792,"user_tz":240,"elapsed":15072,"user":{"displayName":"Vruthik Thakkar","userId":"03035406201152502707"}},"outputId":"30f932fd-106c-403b-fa24-d53aca616292"}},{"cell_type":"code","source":["from functools import partial\n","from tqdm import tqdm\n","tqdm = partial(tqdm, position=0, leave=True)"],"metadata":{"id":"fqp0AY2UGOzg","executionInfo":{"status":"ok","timestamp":1648564461766,"user_tz":240,"elapsed":3,"user":{"displayName":"Vruthik Thakkar","userId":"03035406201152502707"}}},"execution_count":10,"outputs":[]},{"cell_type":"code","execution_count":4,"source":["from model import train\n","from model import BertClassifier"],"outputs":[],"metadata":{"id":"nGKy19B2xr--","executionInfo":{"status":"ok","timestamp":1648563920383,"user_tz":240,"elapsed":1594,"user":{"displayName":"Vruthik Thakkar","userId":"03035406201152502707"}}}},{"cell_type":"markdown","source":["# Dataset"],"metadata":{"id":"ZA649mU3NJKR"}},{"cell_type":"code","execution_count":5,"source":["np.random.seed(112)\n","\n","df = pd.read_csv(os.path.join(GOOGLE_DRIVE_PATH, 'data/MBIC/labeled_dataset.csv'))\n","\n","df_train, df_val, df_test = np.split(df.sample(frac=1, random_state=42), [int(.8*len(df)), int(.9*len(df))])"],"outputs":[],"metadata":{"id":"QU-goqFPb6yG","executionInfo":{"status":"ok","timestamp":1648563921222,"user_tz":240,"elapsed":841,"user":{"displayName":"Vruthik Thakkar","userId":"03035406201152502707"}}}},{"cell_type":"markdown","source":["# Hyperparameter Tuning"],"metadata":{"id":"ibPIe4xeNC7B"}},{"cell_type":"code","execution_count":19,"source":["# Hyperparameter Tuning Helper Function\n","from model import Dataset\n","def hyperparameter_tuning_helper(model_val, batch_size):\n","  use_cuda = torch.cuda.is_available()\n","  device = torch.device(\"cuda\" if use_cuda else \"cpu\")\n","\n","  # model_val = BertClassifier()\n","  # check what checkpoint you need to load from\n","  # state_dict = torch.load(os.path.join(GOOGLE_DRIVE_PATH, checkpoint_path))\n","  # model_val.load_state_dict(state_dict)\n","  # model_val.to(device)\n","\n","  validation_data = Dataset(df_val)\n","  val_dataloader = torch.utils.data.DataLoader(validation_data, batch_size=batch_size, shuffle=True)\n","\n","  total_acc_val = 0\n","  with torch.no_grad():\n","    for val_input, val_label in tqdm(val_dataloader):\n","\n","        val_label = val_label.to(device)\n","        mask = val_input['attention_mask'].to(device)\n","        input_id = val_input['input_ids'].squeeze(1).to(device)\n","\n","        output = model_val(input_id, mask)\n","        acc = (output.argmax(dim=1) == val_label).sum().item()\n","        total_acc_val += acc\n","        \n","  print()\n","  print(\"Validation Accuracy of\", total_acc_val/len(df_val))\n","  return total_acc_val"],"outputs":[],"metadata":{"id":"CnCu26X2spPv","executionInfo":{"status":"ok","timestamp":1648525454621,"user_tz":240,"elapsed":208,"user":{"displayName":"Vruthik Thakkar","userId":"03035406201152502707"}}}},{"cell_type":"markdown","source":["Hyperparameter Tuning on Validation Set"],"metadata":{"id":"JnGAJqQ-spPw"}},{"cell_type":"code","execution_count":20,"source":["from transformers.utils.dummy_pt_objects import BeitForMaskedImageModeling\n","# epoch_list = [3, 5, 10, 15, 20]\n","learning_rate_list = [1e-6, 1e-5, 1e-4]\n","hidden_sizes = [128, 256, 512]\n","batch_sizes = [16, 8, 4, 2]\n","\n","model_iteration = 0\n","best_validation_accuracy = 0\n","best_hyperparameters = {\n","                            \"learning_rate\": None,\n","                            \"hidden_size\": None,\n","                            \"batch_size\": None\n","                            }\n","\n","epoch_value = 5\n","# for epoch_value in epoch_list:\n","for hidden_size in hidden_sizes:\n","  for learning_rate in learning_rate_list:\n","    for batch_size in batch_sizes:\n","      print(hidden_size, learning_rate, batch_size)\n","      bert_clf = BertClassifier()\n","      # checkpoint_string = \"checkpoint_hyperparameter_tuning_\" + str(model_iteration) + \".pth\"\n","      train(bert_clf, df_train, df_val, learning_rate, epoch_value)\n","      # torch.save(bert_clf.state_dict(), os.path.join(GOOGLE_DRIVE_PATH, checkpoint_string))\n","      # files.download(os.path.join(GOOGLE_DRIVE_PATH, checkpoint_string))\n","      # test_model_helper(checkpoint_string)\n","      # state_dict = bert_clf.state_dict()\n","\n","      current_val_accuracy = hyperparameter_tuning_helper(bert_clf, batch_size)\n","\n","      if current_val_accuracy > best_validation_accuracy:\n","          best_validation_accuracy = current_val_accuracy\n","          best_hyperparameters[\"hidden_size\"] = hidden_size\n","          best_hyperparameters[\"learning_rate\"] = learning_rate\n","          best_hyperparameters[\"batch_size\"] = batch_size\n","\n","      model_iteration += 1\n","\n","print(\"The highest accuracy achieved by the model was:\", best_validation_accuracy)\n","print(\"Best Hyperparameters:\", best_hyperparameters)"],"outputs":[{"output_type":"stream","name":"stdout","text":["128 1e-06 16\n"]},{"output_type":"stream","name":"stderr","text":["Some weights of the model checkpoint at bert-base-cased were not used when initializing BertModel: ['cls.seq_relationship.weight', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.dense.weight', 'cls.seq_relationship.bias', 'cls.predictions.decoder.weight', 'cls.predictions.bias', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.transform.dense.bias']\n","- This IS expected if you are initializing BertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n","- This IS NOT expected if you are initializing BertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"]},{"output_type":"stream","name":"stdout","text":["Using Cuda: True\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 680/680 [01:32<00:00,  7.34it/s]\n"]},{"output_type":"stream","name":"stdout","text":["Epochs: 1 | Train Loss:  0.540             | Train Accuracy:  0.433             | Val Loss:  0.533             | Val Accuracy:  0.476\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 680/680 [01:32<00:00,  7.37it/s]\n"]},{"output_type":"stream","name":"stdout","text":["Epochs: 2 | Train Loss:  0.492             | Train Accuracy:  0.605             | Val Loss:  0.472             | Val Accuracy:  0.624\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 680/680 [01:32<00:00,  7.38it/s]\n"]},{"output_type":"stream","name":"stdout","text":["Epochs: 3 | Train Loss:  0.383             | Train Accuracy:  0.803             | Val Loss:  0.375             | Val Accuracy:  0.747\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 680/680 [01:32<00:00,  7.37it/s]\n"]},{"output_type":"stream","name":"stdout","text":["Epochs: 4 | Train Loss:  0.275             | Train Accuracy:  0.911             | Val Loss:  0.309             | Val Accuracy:  0.812\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 680/680 [01:32<00:00,  7.33it/s]\n"]},{"output_type":"stream","name":"stdout","text":["Epochs: 5 | Train Loss:  0.197             | Train Accuracy:  0.949             | Val Loss:  0.264             | Val Accuracy:  0.812\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 11/11 [00:03<00:00,  3.53it/s]\n"]},{"output_type":"stream","name":"stdout","text":["\n","Validation Accuracy of 0.8411764705882353\n","128 1e-06 8\n"]},{"output_type":"stream","name":"stderr","text":["Some weights of the model checkpoint at bert-base-cased were not used when initializing BertModel: ['cls.seq_relationship.weight', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.dense.weight', 'cls.seq_relationship.bias', 'cls.predictions.decoder.weight', 'cls.predictions.bias', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.transform.dense.bias']\n","- This IS expected if you are initializing BertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n","- This IS NOT expected if you are initializing BertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"]},{"output_type":"stream","name":"stdout","text":["Using Cuda: True\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 680/680 [01:32<00:00,  7.38it/s]\n"]},{"output_type":"stream","name":"stdout","text":["Epochs: 1 | Train Loss:  0.545             | Train Accuracy:  0.393             | Val Loss:  0.533             | Val Accuracy:  0.512\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 680/680 [01:32<00:00,  7.38it/s]\n"]},{"output_type":"stream","name":"stdout","text":["Epochs: 2 | Train Loss:  0.505             | Train Accuracy:  0.548             | Val Loss:  0.481             | Val Accuracy:  0.612\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 680/680 [01:32<00:00,  7.38it/s]\n"]},{"output_type":"stream","name":"stdout","text":["Epochs: 3 | Train Loss:  0.407             | Train Accuracy:  0.782             | Val Loss:  0.394             | Val Accuracy:  0.765\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 680/680 [01:32<00:00,  7.37it/s]\n"]},{"output_type":"stream","name":"stdout","text":["Epochs: 4 | Train Loss:  0.300             | Train Accuracy:  0.900             | Val Loss:  0.324             | Val Accuracy:  0.812\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 680/680 [01:32<00:00,  7.38it/s]\n"]},{"output_type":"stream","name":"stdout","text":["Epochs: 5 | Train Loss:  0.211             | Train Accuracy:  0.956             | Val Loss:  0.287             | Val Accuracy:  0.841\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 22/22 [00:03<00:00,  6.80it/s]\n"]},{"output_type":"stream","name":"stdout","text":["\n","Validation Accuracy of 0.8470588235294118\n","128 1e-06 4\n"]},{"output_type":"stream","name":"stderr","text":["Some weights of the model checkpoint at bert-base-cased were not used when initializing BertModel: ['cls.seq_relationship.weight', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.dense.weight', 'cls.seq_relationship.bias', 'cls.predictions.decoder.weight', 'cls.predictions.bias', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.transform.dense.bias']\n","- This IS expected if you are initializing BertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n","- This IS NOT expected if you are initializing BertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"]},{"output_type":"stream","name":"stdout","text":["Using Cuda: True\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 680/680 [01:32<00:00,  7.38it/s]\n"]},{"output_type":"stream","name":"stdout","text":["Epochs: 1 | Train Loss:  0.545             | Train Accuracy:  0.397             | Val Loss:  0.528             | Val Accuracy:  0.541\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 680/680 [01:32<00:00,  7.38it/s]\n"]},{"output_type":"stream","name":"stdout","text":["Epochs: 2 | Train Loss:  0.485             | Train Accuracy:  0.621             | Val Loss:  0.458             | Val Accuracy:  0.694\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 680/680 [01:32<00:00,  7.38it/s]\n"]},{"output_type":"stream","name":"stdout","text":["Epochs: 3 | Train Loss:  0.381             | Train Accuracy:  0.773             | Val Loss:  0.371             | Val Accuracy:  0.765\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 680/680 [01:32<00:00,  7.37it/s]\n"]},{"output_type":"stream","name":"stdout","text":["Epochs: 4 | Train Loss:  0.291             | Train Accuracy:  0.840             | Val Loss:  0.332             | Val Accuracy:  0.771\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 680/680 [01:32<00:00,  7.38it/s]\n"]},{"output_type":"stream","name":"stdout","text":["Epochs: 5 | Train Loss:  0.226             | Train Accuracy:  0.875             | Val Loss:  0.302             | Val Accuracy:  0.806\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 43/43 [00:03<00:00, 12.96it/s]\n"]},{"output_type":"stream","name":"stdout","text":["\n","Validation Accuracy of 0.8\n","128 1e-06 2\n"]},{"output_type":"stream","name":"stderr","text":["Some weights of the model checkpoint at bert-base-cased were not used when initializing BertModel: ['cls.seq_relationship.weight', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.dense.weight', 'cls.seq_relationship.bias', 'cls.predictions.decoder.weight', 'cls.predictions.bias', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.transform.dense.bias']\n","- This IS expected if you are initializing BertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n","- This IS NOT expected if you are initializing BertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"]},{"output_type":"stream","name":"stdout","text":["Using Cuda: True\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 680/680 [01:32<00:00,  7.38it/s]\n"]},{"output_type":"stream","name":"stdout","text":["Epochs: 1 | Train Loss:  0.531             | Train Accuracy:  0.432             | Val Loss:  0.518             | Val Accuracy:  0.441\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 680/680 [01:32<00:00,  7.38it/s]\n"]},{"output_type":"stream","name":"stdout","text":["Epochs: 2 | Train Loss:  0.475             | Train Accuracy:  0.580             | Val Loss:  0.439             | Val Accuracy:  0.653\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 680/680 [01:32<00:00,  7.38it/s]\n"]},{"output_type":"stream","name":"stdout","text":["Epochs: 3 | Train Loss:  0.377             | Train Accuracy:  0.751             | Val Loss:  0.380             | Val Accuracy:  0.729\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 680/680 [01:32<00:00,  7.38it/s]\n"]},{"output_type":"stream","name":"stdout","text":["Epochs: 4 | Train Loss:  0.303             | Train Accuracy:  0.824             | Val Loss:  0.345             | Val Accuracy:  0.747\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 680/680 [01:32<00:00,  7.38it/s]\n"]},{"output_type":"stream","name":"stdout","text":["Epochs: 5 | Train Loss:  0.256             | Train Accuracy:  0.841             | Val Loss:  0.326             | Val Accuracy:  0.765\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 85/85 [00:03<00:00, 23.86it/s]\n"]},{"output_type":"stream","name":"stdout","text":["\n","Validation Accuracy of 0.7588235294117647\n","128 1e-05 16\n"]},{"output_type":"stream","name":"stderr","text":["Some weights of the model checkpoint at bert-base-cased were not used when initializing BertModel: ['cls.seq_relationship.weight', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.dense.weight', 'cls.seq_relationship.bias', 'cls.predictions.decoder.weight', 'cls.predictions.bias', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.transform.dense.bias']\n","- This IS expected if you are initializing BertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n","- This IS NOT expected if you are initializing BertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"]},{"output_type":"stream","name":"stdout","text":["Using Cuda: True\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 680/680 [01:32<00:00,  7.38it/s]\n"]},{"output_type":"stream","name":"stdout","text":["Epochs: 1 | Train Loss:  0.497             | Train Accuracy:  0.498             | Val Loss:  0.426             | Val Accuracy:  0.588\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 680/680 [01:32<00:00,  7.38it/s]\n"]},{"output_type":"stream","name":"stdout","text":["Epochs: 2 | Train Loss:  0.307             | Train Accuracy:  0.751             | Val Loss:  0.241             | Val Accuracy:  0.853\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 680/680 [01:32<00:00,  7.38it/s]\n"]},{"output_type":"stream","name":"stdout","text":["Epochs: 3 | Train Loss:  0.151             | Train Accuracy:  0.915             | Val Loss:  0.220             | Val Accuracy:  0.859\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 680/680 [01:32<00:00,  7.38it/s]\n"]},{"output_type":"stream","name":"stdout","text":["Epochs: 4 | Train Loss:  0.094             | Train Accuracy:  0.954             | Val Loss:  0.158             | Val Accuracy:  0.906\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 680/680 [01:32<00:00,  7.38it/s]\n"]},{"output_type":"stream","name":"stdout","text":["Epochs: 5 | Train Loss:  0.056             | Train Accuracy:  0.976             | Val Loss:  0.176             | Val Accuracy:  0.882\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 11/11 [00:03<00:00,  3.52it/s]\n"]},{"output_type":"stream","name":"stdout","text":["\n","Validation Accuracy of 0.8823529411764706\n","128 1e-05 8\n"]},{"output_type":"stream","name":"stderr","text":["Some weights of the model checkpoint at bert-base-cased were not used when initializing BertModel: ['cls.seq_relationship.weight', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.dense.weight', 'cls.seq_relationship.bias', 'cls.predictions.decoder.weight', 'cls.predictions.bias', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.transform.dense.bias']\n","- This IS expected if you are initializing BertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n","- This IS NOT expected if you are initializing BertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"]},{"output_type":"stream","name":"stdout","text":["Using Cuda: True\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 680/680 [01:32<00:00,  7.37it/s]\n"]},{"output_type":"stream","name":"stdout","text":["Epochs: 1 | Train Loss:  0.496             | Train Accuracy:  0.519             | Val Loss:  0.485             | Val Accuracy:  0.494\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 680/680 [01:32<00:00,  7.38it/s]\n"]},{"output_type":"stream","name":"stdout","text":["Epochs: 2 | Train Loss:  0.398             | Train Accuracy:  0.642             | Val Loss:  0.326             | Val Accuracy:  0.753\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 680/680 [01:32<00:00,  7.38it/s]\n"]},{"output_type":"stream","name":"stdout","text":["Epochs: 3 | Train Loss:  0.192             | Train Accuracy:  0.874             | Val Loss:  0.227             | Val Accuracy:  0.847\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 680/680 [01:32<00:00,  7.38it/s]\n"]},{"output_type":"stream","name":"stdout","text":["Epochs: 4 | Train Loss:  0.091             | Train Accuracy:  0.946             | Val Loss:  0.191             | Val Accuracy:  0.876\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 680/680 [01:32<00:00,  7.38it/s]\n"]},{"output_type":"stream","name":"stdout","text":["Epochs: 5 | Train Loss:  0.059             | Train Accuracy:  0.964             | Val Loss:  0.113             | Val Accuracy:  0.947\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 22/22 [00:03<00:00,  6.81it/s]\n"]},{"output_type":"stream","name":"stdout","text":["\n","Validation Accuracy of 0.9411764705882353\n","128 1e-05 4\n"]},{"output_type":"stream","name":"stderr","text":["Some weights of the model checkpoint at bert-base-cased were not used when initializing BertModel: ['cls.seq_relationship.weight', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.dense.weight', 'cls.seq_relationship.bias', 'cls.predictions.decoder.weight', 'cls.predictions.bias', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.transform.dense.bias']\n","- This IS expected if you are initializing BertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n","- This IS NOT expected if you are initializing BertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"]},{"output_type":"stream","name":"stdout","text":["Using Cuda: True\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 680/680 [01:32<00:00,  7.38it/s]\n"]},{"output_type":"stream","name":"stdout","text":["Epochs: 1 | Train Loss:  0.407             | Train Accuracy:  0.639             | Val Loss:  0.327             | Val Accuracy:  0.753\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 680/680 [01:32<00:00,  7.38it/s]\n"]},{"output_type":"stream","name":"stdout","text":["Epochs: 2 | Train Loss:  0.152             | Train Accuracy:  0.900             | Val Loss:  0.161             | Val Accuracy:  0.876\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 680/680 [01:32<00:00,  7.31it/s]\n"]},{"output_type":"stream","name":"stdout","text":["Epochs: 3 | Train Loss:  0.051             | Train Accuracy:  0.971             | Val Loss:  0.105             | Val Accuracy:  0.953\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 680/680 [01:33<00:00,  7.30it/s]\n"]},{"output_type":"stream","name":"stdout","text":["Epochs: 4 | Train Loss:  0.034             | Train Accuracy:  0.982             | Val Loss:  0.147             | Val Accuracy:  0.918\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 680/680 [01:32<00:00,  7.33it/s]\n"]},{"output_type":"stream","name":"stdout","text":["Epochs: 5 | Train Loss:  0.031             | Train Accuracy:  0.985             | Val Loss:  0.223             | Val Accuracy:  0.882\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 43/43 [00:03<00:00, 12.98it/s]\n"]},{"output_type":"stream","name":"stdout","text":["\n","Validation Accuracy of 0.8705882352941177\n","128 1e-05 2\n"]},{"output_type":"stream","name":"stderr","text":["Some weights of the model checkpoint at bert-base-cased were not used when initializing BertModel: ['cls.seq_relationship.weight', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.dense.weight', 'cls.seq_relationship.bias', 'cls.predictions.decoder.weight', 'cls.predictions.bias', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.transform.dense.bias']\n","- This IS expected if you are initializing BertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n","- This IS NOT expected if you are initializing BertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"]},{"output_type":"stream","name":"stdout","text":["Using Cuda: True\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 680/680 [01:34<00:00,  7.22it/s]\n"]},{"output_type":"stream","name":"stdout","text":["Epochs: 1 | Train Loss:  0.472             | Train Accuracy:  0.494             | Val Loss:  0.381             | Val Accuracy:  0.624\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 680/680 [01:32<00:00,  7.38it/s]\n"]},{"output_type":"stream","name":"stdout","text":["Epochs: 2 | Train Loss:  0.278             | Train Accuracy:  0.707             | Val Loss:  0.288             | Val Accuracy:  0.700\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 680/680 [01:32<00:00,  7.38it/s]\n"]},{"output_type":"stream","name":"stdout","text":["Epochs: 3 | Train Loss:  0.176             | Train Accuracy:  0.784             | Val Loss:  0.220             | Val Accuracy:  0.724\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 680/680 [01:32<00:00,  7.37it/s]\n"]},{"output_type":"stream","name":"stdout","text":["Epochs: 4 | Train Loss:  0.134             | Train Accuracy:  0.804             | Val Loss:  0.223             | Val Accuracy:  0.724\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 680/680 [01:32<00:00,  7.38it/s]\n"]},{"output_type":"stream","name":"stdout","text":["Epochs: 5 | Train Loss:  0.117             | Train Accuracy:  0.810             | Val Loss:  0.236             | Val Accuracy:  0.735\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 85/85 [00:03<00:00, 23.84it/s]\n"]},{"output_type":"stream","name":"stdout","text":["\n","Validation Accuracy of 0.7294117647058823\n","128 0.0001 16\n"]},{"output_type":"stream","name":"stderr","text":["Some weights of the model checkpoint at bert-base-cased were not used when initializing BertModel: ['cls.seq_relationship.weight', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.dense.weight', 'cls.seq_relationship.bias', 'cls.predictions.decoder.weight', 'cls.predictions.bias', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.transform.dense.bias']\n","- This IS expected if you are initializing BertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n","- This IS NOT expected if you are initializing BertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"]},{"output_type":"stream","name":"stdout","text":["Using Cuda: True\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 680/680 [01:32<00:00,  7.38it/s]\n"]},{"output_type":"stream","name":"stdout","text":["Epochs: 1 | Train Loss:  0.522             | Train Accuracy:  0.439             | Val Loss:  0.549             | Val Accuracy:  0.388\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 680/680 [01:32<00:00,  7.37it/s]\n"]},{"output_type":"stream","name":"stdout","text":["Epochs: 2 | Train Loss:  0.549             | Train Accuracy:  0.404             | Val Loss:  0.549             | Val Accuracy:  0.388\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 680/680 [01:32<00:00,  7.33it/s]\n"]},{"output_type":"stream","name":"stdout","text":["Epochs: 3 | Train Loss:  0.549             | Train Accuracy:  0.404             | Val Loss:  0.549             | Val Accuracy:  0.388\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 680/680 [01:32<00:00,  7.35it/s]\n"]},{"output_type":"stream","name":"stdout","text":["Epochs: 4 | Train Loss:  0.549             | Train Accuracy:  0.404             | Val Loss:  0.549             | Val Accuracy:  0.388\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 680/680 [01:32<00:00,  7.35it/s]\n"]},{"output_type":"stream","name":"stdout","text":["Epochs: 5 | Train Loss:  0.549             | Train Accuracy:  0.404             | Val Loss:  0.549             | Val Accuracy:  0.388\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 11/11 [00:03<00:00,  3.53it/s]\n"]},{"output_type":"stream","name":"stdout","text":["\n","Validation Accuracy of 0.38823529411764707\n","128 0.0001 8\n"]},{"output_type":"stream","name":"stderr","text":["Some weights of the model checkpoint at bert-base-cased were not used when initializing BertModel: ['cls.seq_relationship.weight', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.dense.weight', 'cls.seq_relationship.bias', 'cls.predictions.decoder.weight', 'cls.predictions.bias', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.transform.dense.bias']\n","- This IS expected if you are initializing BertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n","- This IS NOT expected if you are initializing BertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"]},{"output_type":"stream","name":"stdout","text":["Using Cuda: True\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 680/680 [01:32<00:00,  7.38it/s]\n"]},{"output_type":"stream","name":"stdout","text":["Epochs: 1 | Train Loss:  0.548             | Train Accuracy:  0.402             | Val Loss:  0.549             | Val Accuracy:  0.388\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 680/680 [01:32<00:00,  7.36it/s]\n"]},{"output_type":"stream","name":"stdout","text":["Epochs: 2 | Train Loss:  0.549             | Train Accuracy:  0.404             | Val Loss:  0.549             | Val Accuracy:  0.388\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 680/680 [01:32<00:00,  7.35it/s]\n"]},{"output_type":"stream","name":"stdout","text":["Epochs: 3 | Train Loss:  0.549             | Train Accuracy:  0.404             | Val Loss:  0.549             | Val Accuracy:  0.388\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 680/680 [01:32<00:00,  7.35it/s]\n"]},{"output_type":"stream","name":"stdout","text":["Epochs: 4 | Train Loss:  0.549             | Train Accuracy:  0.404             | Val Loss:  0.549             | Val Accuracy:  0.388\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 680/680 [01:32<00:00,  7.35it/s]\n"]},{"output_type":"stream","name":"stdout","text":["Epochs: 5 | Train Loss:  0.549             | Train Accuracy:  0.404             | Val Loss:  0.549             | Val Accuracy:  0.388\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 22/22 [00:03<00:00,  6.81it/s]\n"]},{"output_type":"stream","name":"stdout","text":["\n","Validation Accuracy of 0.38823529411764707\n","128 0.0001 4\n"]},{"output_type":"stream","name":"stderr","text":["Some weights of the model checkpoint at bert-base-cased were not used when initializing BertModel: ['cls.seq_relationship.weight', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.dense.weight', 'cls.seq_relationship.bias', 'cls.predictions.decoder.weight', 'cls.predictions.bias', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.transform.dense.bias']\n","- This IS expected if you are initializing BertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n","- This IS NOT expected if you are initializing BertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"]},{"output_type":"stream","name":"stdout","text":["Using Cuda: True\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 680/680 [01:32<00:00,  7.38it/s]\n"]},{"output_type":"stream","name":"stdout","text":["Epochs: 1 | Train Loss:  0.548             | Train Accuracy:  0.399             | Val Loss:  0.549             | Val Accuracy:  0.388\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 680/680 [01:32<00:00,  7.37it/s]\n"]},{"output_type":"stream","name":"stdout","text":["Epochs: 2 | Train Loss:  0.549             | Train Accuracy:  0.404             | Val Loss:  0.549             | Val Accuracy:  0.388\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 680/680 [01:32<00:00,  7.37it/s]\n"]},{"output_type":"stream","name":"stdout","text":["Epochs: 3 | Train Loss:  0.550             | Train Accuracy:  0.401             | Val Loss:  0.549             | Val Accuracy:  0.388\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 680/680 [01:32<00:00,  7.37it/s]\n"]},{"output_type":"stream","name":"stdout","text":["Epochs: 4 | Train Loss:  0.549             | Train Accuracy:  0.404             | Val Loss:  0.549             | Val Accuracy:  0.388\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 680/680 [01:32<00:00,  7.35it/s]\n"]},{"output_type":"stream","name":"stdout","text":["Epochs: 5 | Train Loss:  0.549             | Train Accuracy:  0.404             | Val Loss:  0.549             | Val Accuracy:  0.388\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 43/43 [00:03<00:00, 12.95it/s]\n"]},{"output_type":"stream","name":"stdout","text":["\n","Validation Accuracy of 0.38823529411764707\n","128 0.0001 2\n"]},{"output_type":"stream","name":"stderr","text":["Some weights of the model checkpoint at bert-base-cased were not used when initializing BertModel: ['cls.seq_relationship.weight', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.dense.weight', 'cls.seq_relationship.bias', 'cls.predictions.decoder.weight', 'cls.predictions.bias', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.transform.dense.bias']\n","- This IS expected if you are initializing BertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n","- This IS NOT expected if you are initializing BertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"]},{"output_type":"stream","name":"stdout","text":["Using Cuda: True\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 680/680 [01:32<00:00,  7.38it/s]\n"]},{"output_type":"stream","name":"stdout","text":["Epochs: 1 | Train Loss:  0.549             | Train Accuracy:  0.401             | Val Loss:  0.549             | Val Accuracy:  0.388\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 680/680 [01:32<00:00,  7.36it/s]\n"]},{"output_type":"stream","name":"stdout","text":["Epochs: 2 | Train Loss:  0.549             | Train Accuracy:  0.403             | Val Loss:  0.549             | Val Accuracy:  0.388\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 680/680 [01:32<00:00,  7.38it/s]\n"]},{"output_type":"stream","name":"stdout","text":["Epochs: 3 | Train Loss:  0.549             | Train Accuracy:  0.404             | Val Loss:  0.549             | Val Accuracy:  0.388\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 680/680 [01:32<00:00,  7.35it/s]\n"]},{"output_type":"stream","name":"stdout","text":["Epochs: 4 | Train Loss:  0.549             | Train Accuracy:  0.404             | Val Loss:  0.549             | Val Accuracy:  0.388\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 680/680 [01:32<00:00,  7.33it/s]\n"]},{"output_type":"stream","name":"stdout","text":["Epochs: 5 | Train Loss:  0.549             | Train Accuracy:  0.404             | Val Loss:  0.549             | Val Accuracy:  0.388\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 85/85 [00:03<00:00, 23.93it/s]\n"]},{"output_type":"stream","name":"stdout","text":["\n","Validation Accuracy of 0.38823529411764707\n","256 1e-06 16\n"]},{"output_type":"stream","name":"stderr","text":["Some weights of the model checkpoint at bert-base-cased were not used when initializing BertModel: ['cls.seq_relationship.weight', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.dense.weight', 'cls.seq_relationship.bias', 'cls.predictions.decoder.weight', 'cls.predictions.bias', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.transform.dense.bias']\n","- This IS expected if you are initializing BertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n","- This IS NOT expected if you are initializing BertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"]},{"output_type":"stream","name":"stdout","text":["Using Cuda: True\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 680/680 [01:32<00:00,  7.37it/s]\n"]},{"output_type":"stream","name":"stdout","text":["Epochs: 1 | Train Loss:  0.530             | Train Accuracy:  0.488             | Val Loss:  0.519             | Val Accuracy:  0.482\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 680/680 [01:32<00:00,  7.36it/s]\n"]},{"output_type":"stream","name":"stdout","text":["Epochs: 2 | Train Loss:  0.481             | Train Accuracy:  0.607             | Val Loss:  0.465             | Val Accuracy:  0.618\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 680/680 [01:32<00:00,  7.36it/s]\n"]},{"output_type":"stream","name":"stdout","text":["Epochs: 3 | Train Loss:  0.410             | Train Accuracy:  0.710             | Val Loss:  0.405             | Val Accuracy:  0.700\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 680/680 [01:32<00:00,  7.35it/s]\n"]},{"output_type":"stream","name":"stdout","text":["Epochs: 4 | Train Loss:  0.328             | Train Accuracy:  0.789             | Val Loss:  0.343             | Val Accuracy:  0.771\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 680/680 [01:32<00:00,  7.33it/s]\n"]},{"output_type":"stream","name":"stdout","text":["Epochs: 5 | Train Loss:  0.246             | Train Accuracy:  0.887             | Val Loss:  0.293             | Val Accuracy:  0.829\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 11/11 [00:03<00:00,  3.51it/s]\n"]},{"output_type":"stream","name":"stdout","text":["\n","Validation Accuracy of 0.8235294117647058\n","256 1e-06 8\n"]},{"output_type":"stream","name":"stderr","text":["Some weights of the model checkpoint at bert-base-cased were not used when initializing BertModel: ['cls.seq_relationship.weight', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.dense.weight', 'cls.seq_relationship.bias', 'cls.predictions.decoder.weight', 'cls.predictions.bias', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.transform.dense.bias']\n","- This IS expected if you are initializing BertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n","- This IS NOT expected if you are initializing BertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"]},{"output_type":"stream","name":"stdout","text":["Using Cuda: True\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 680/680 [01:32<00:00,  7.33it/s]\n"]},{"output_type":"stream","name":"stdout","text":["Epochs: 1 | Train Loss:  0.535             | Train Accuracy:  0.454             | Val Loss:  0.522             | Val Accuracy:  0.512\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 680/680 [01:32<00:00,  7.33it/s]\n"]},{"output_type":"stream","name":"stdout","text":["Epochs: 2 | Train Loss:  0.482             | Train Accuracy:  0.619             | Val Loss:  0.474             | Val Accuracy:  0.612\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 680/680 [01:32<00:00,  7.33it/s]\n"]},{"output_type":"stream","name":"stdout","text":["Epochs: 3 | Train Loss:  0.401             | Train Accuracy:  0.743             | Val Loss:  0.426             | Val Accuracy:  0.659\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 680/680 [01:32<00:00,  7.33it/s]\n"]},{"output_type":"stream","name":"stdout","text":["Epochs: 4 | Train Loss:  0.329             | Train Accuracy:  0.792             | Val Loss:  0.394             | Val Accuracy:  0.700\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 680/680 [01:32<00:00,  7.33it/s]\n"]},{"output_type":"stream","name":"stdout","text":["Epochs: 5 | Train Loss:  0.245             | Train Accuracy:  0.885             | Val Loss:  0.309             | Val Accuracy:  0.800\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 22/22 [00:03<00:00,  6.75it/s]\n"]},{"output_type":"stream","name":"stdout","text":["\n","Validation Accuracy of 0.7941176470588235\n","256 1e-06 4\n"]},{"output_type":"stream","name":"stderr","text":["Some weights of the model checkpoint at bert-base-cased were not used when initializing BertModel: ['cls.seq_relationship.weight', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.dense.weight', 'cls.seq_relationship.bias', 'cls.predictions.decoder.weight', 'cls.predictions.bias', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.transform.dense.bias']\n","- This IS expected if you are initializing BertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n","- This IS NOT expected if you are initializing BertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"]},{"output_type":"stream","name":"stdout","text":["Using Cuda: True\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 680/680 [01:32<00:00,  7.33it/s]\n"]},{"output_type":"stream","name":"stdout","text":["Epochs: 1 | Train Loss:  0.541             | Train Accuracy:  0.412             | Val Loss:  0.529             | Val Accuracy:  0.488\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 680/680 [01:32<00:00,  7.35it/s]\n"]},{"output_type":"stream","name":"stdout","text":["Epochs: 2 | Train Loss:  0.503             | Train Accuracy:  0.525             | Val Loss:  0.477             | Val Accuracy:  0.600\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 680/680 [01:32<00:00,  7.38it/s]\n"]},{"output_type":"stream","name":"stdout","text":["Epochs: 3 | Train Loss:  0.416             | Train Accuracy:  0.743             | Val Loss:  0.404             | Val Accuracy:  0.782\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 680/680 [01:32<00:00,  7.38it/s]\n"]},{"output_type":"stream","name":"stdout","text":["Epochs: 4 | Train Loss:  0.322             | Train Accuracy:  0.888             | Val Loss:  0.344             | Val Accuracy:  0.800\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 680/680 [01:32<00:00,  7.37it/s]\n"]},{"output_type":"stream","name":"stdout","text":["Epochs: 5 | Train Loss:  0.241             | Train Accuracy:  0.940             | Val Loss:  0.299             | Val Accuracy:  0.829\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 43/43 [00:03<00:00, 12.91it/s]\n"]},{"output_type":"stream","name":"stdout","text":["\n","Validation Accuracy of 0.8176470588235294\n","256 1e-06 2\n"]},{"output_type":"stream","name":"stderr","text":["Some weights of the model checkpoint at bert-base-cased were not used when initializing BertModel: ['cls.seq_relationship.weight', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.dense.weight', 'cls.seq_relationship.bias', 'cls.predictions.decoder.weight', 'cls.predictions.bias', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.transform.dense.bias']\n","- This IS expected if you are initializing BertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n","- This IS NOT expected if you are initializing BertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"]},{"output_type":"stream","name":"stdout","text":["Using Cuda: True\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 680/680 [01:32<00:00,  7.38it/s]\n"]},{"output_type":"stream","name":"stdout","text":["Epochs: 1 | Train Loss:  0.531             | Train Accuracy:  0.417             | Val Loss:  0.511             | Val Accuracy:  0.459\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 680/680 [01:32<00:00,  7.38it/s]\n"]},{"output_type":"stream","name":"stdout","text":["Epochs: 2 | Train Loss:  0.480             | Train Accuracy:  0.551             | Val Loss:  0.468             | Val Accuracy:  0.635\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 680/680 [01:32<00:00,  7.38it/s]\n"]},{"output_type":"stream","name":"stdout","text":["Epochs: 3 | Train Loss:  0.418             | Train Accuracy:  0.723             | Val Loss:  0.406             | Val Accuracy:  0.700\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 680/680 [01:32<00:00,  7.38it/s]\n"]},{"output_type":"stream","name":"stdout","text":["Epochs: 4 | Train Loss:  0.296             | Train Accuracy:  0.899             | Val Loss:  0.312             | Val Accuracy:  0.829\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 680/680 [01:32<00:00,  7.38it/s]\n"]},{"output_type":"stream","name":"stdout","text":["Epochs: 5 | Train Loss:  0.213             | Train Accuracy:  0.934             | Val Loss:  0.273             | Val Accuracy:  0.835\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 85/85 [00:03<00:00, 23.91it/s]\n"]},{"output_type":"stream","name":"stdout","text":["\n","Validation Accuracy of 0.8352941176470589\n","256 1e-05 16\n"]},{"output_type":"stream","name":"stderr","text":["Some weights of the model checkpoint at bert-base-cased were not used when initializing BertModel: ['cls.seq_relationship.weight', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.dense.weight', 'cls.seq_relationship.bias', 'cls.predictions.decoder.weight', 'cls.predictions.bias', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.transform.dense.bias']\n","- This IS expected if you are initializing BertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n","- This IS NOT expected if you are initializing BertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"]},{"output_type":"stream","name":"stdout","text":["Using Cuda: True\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 680/680 [01:32<00:00,  7.38it/s]\n"]},{"output_type":"stream","name":"stdout","text":["Epochs: 1 | Train Loss:  0.519             | Train Accuracy:  0.457             | Val Loss:  0.466             | Val Accuracy:  0.535\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 680/680 [01:32<00:00,  7.38it/s]\n"]},{"output_type":"stream","name":"stdout","text":["Epochs: 2 | Train Loss:  0.302             | Train Accuracy:  0.783             | Val Loss:  0.222             | Val Accuracy:  0.871\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 680/680 [01:32<00:00,  7.38it/s]\n"]},{"output_type":"stream","name":"stdout","text":["Epochs: 3 | Train Loss:  0.109             | Train Accuracy:  0.945             | Val Loss:  0.159             | Val Accuracy:  0.894\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 680/680 [01:32<00:00,  7.38it/s]\n"]},{"output_type":"stream","name":"stdout","text":["Epochs: 4 | Train Loss:  0.047             | Train Accuracy:  0.982             | Val Loss:  0.165             | Val Accuracy:  0.912\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 680/680 [01:32<00:00,  7.38it/s]\n"]},{"output_type":"stream","name":"stdout","text":["Epochs: 5 | Train Loss:  0.034             | Train Accuracy:  0.988             | Val Loss:  0.145             | Val Accuracy:  0.918\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 11/11 [00:03<00:00,  3.52it/s]\n"]},{"output_type":"stream","name":"stdout","text":["\n","Validation Accuracy of 0.9117647058823529\n","256 1e-05 8\n"]},{"output_type":"stream","name":"stderr","text":["Some weights of the model checkpoint at bert-base-cased were not used when initializing BertModel: ['cls.seq_relationship.weight', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.dense.weight', 'cls.seq_relationship.bias', 'cls.predictions.decoder.weight', 'cls.predictions.bias', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.transform.dense.bias']\n","- This IS expected if you are initializing BertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n","- This IS NOT expected if you are initializing BertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"]},{"output_type":"stream","name":"stdout","text":["Using Cuda: True\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 680/680 [01:32<00:00,  7.38it/s]\n"]},{"output_type":"stream","name":"stdout","text":["Epochs: 1 | Train Loss:  0.458             | Train Accuracy:  0.566             | Val Loss:  0.341             | Val Accuracy:  0.759\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 680/680 [01:32<00:00,  7.38it/s]\n"]},{"output_type":"stream","name":"stdout","text":["Epochs: 2 | Train Loss:  0.212             | Train Accuracy:  0.860             | Val Loss:  0.186             | Val Accuracy:  0.876\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 680/680 [01:32<00:00,  7.38it/s]\n"]},{"output_type":"stream","name":"stdout","text":["Epochs: 3 | Train Loss:  0.083             | Train Accuracy:  0.954             | Val Loss:  0.161             | Val Accuracy:  0.888\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 680/680 [01:32<00:00,  7.38it/s]\n"]},{"output_type":"stream","name":"stdout","text":["Epochs: 4 | Train Loss:  0.042             | Train Accuracy:  0.979             | Val Loss:  0.131             | Val Accuracy:  0.941\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 680/680 [01:32<00:00,  7.38it/s]\n"]},{"output_type":"stream","name":"stdout","text":["Epochs: 5 | Train Loss:  0.022             | Train Accuracy:  0.993             | Val Loss:  0.158             | Val Accuracy:  0.924\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 22/22 [00:03<00:00,  6.79it/s]\n"]},{"output_type":"stream","name":"stdout","text":["\n","Validation Accuracy of 0.9235294117647059\n","256 1e-05 4\n"]},{"output_type":"stream","name":"stderr","text":["Some weights of the model checkpoint at bert-base-cased were not used when initializing BertModel: ['cls.seq_relationship.weight', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.dense.weight', 'cls.seq_relationship.bias', 'cls.predictions.decoder.weight', 'cls.predictions.bias', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.transform.dense.bias']\n","- This IS expected if you are initializing BertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n","- This IS NOT expected if you are initializing BertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"]},{"output_type":"stream","name":"stdout","text":["Using Cuda: True\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 680/680 [01:32<00:00,  7.38it/s]\n"]},{"output_type":"stream","name":"stdout","text":["Epochs: 1 | Train Loss:  0.515             | Train Accuracy:  0.502             | Val Loss:  0.497             | Val Accuracy:  0.518\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 680/680 [01:32<00:00,  7.38it/s]\n"]},{"output_type":"stream","name":"stdout","text":["Epochs: 2 | Train Loss:  0.482             | Train Accuracy:  0.524             | Val Loss:  0.478             | Val Accuracy:  0.471\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 680/680 [01:32<00:00,  7.38it/s]\n"]},{"output_type":"stream","name":"stdout","text":["Epochs: 3 | Train Loss:  0.336             | Train Accuracy:  0.725             | Val Loss:  0.263             | Val Accuracy:  0.841\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 680/680 [01:32<00:00,  7.37it/s]\n"]},{"output_type":"stream","name":"stdout","text":["Epochs: 4 | Train Loss:  0.143             | Train Accuracy:  0.910             | Val Loss:  0.290             | Val Accuracy:  0.812\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 680/680 [01:32<00:00,  7.38it/s]\n"]},{"output_type":"stream","name":"stdout","text":["Epochs: 5 | Train Loss:  0.082             | Train Accuracy:  0.954             | Val Loss:  0.166             | Val Accuracy:  0.894\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 43/43 [00:03<00:00, 12.99it/s]\n"]},{"output_type":"stream","name":"stdout","text":["\n","Validation Accuracy of 0.9\n","256 1e-05 2\n"]},{"output_type":"stream","name":"stderr","text":["Some weights of the model checkpoint at bert-base-cased were not used when initializing BertModel: ['cls.seq_relationship.weight', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.dense.weight', 'cls.seq_relationship.bias', 'cls.predictions.decoder.weight', 'cls.predictions.bias', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.transform.dense.bias']\n","- This IS expected if you are initializing BertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n","- This IS NOT expected if you are initializing BertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"]},{"output_type":"stream","name":"stdout","text":["Using Cuda: True\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 680/680 [01:32<00:00,  7.38it/s]\n"]},{"output_type":"stream","name":"stdout","text":["Epochs: 1 | Train Loss:  0.491             | Train Accuracy:  0.530             | Val Loss:  0.405             | Val Accuracy:  0.635\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 680/680 [01:32<00:00,  7.38it/s]\n"]},{"output_type":"stream","name":"stdout","text":["Epochs: 2 | Train Loss:  0.275             | Train Accuracy:  0.824             | Val Loss:  0.191             | Val Accuracy:  0.894\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 680/680 [01:32<00:00,  7.38it/s]\n"]},{"output_type":"stream","name":"stdout","text":["Epochs: 3 | Train Loss:  0.118             | Train Accuracy:  0.938             | Val Loss:  0.155             | Val Accuracy:  0.924\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 680/680 [01:32<00:00,  7.38it/s]\n"]},{"output_type":"stream","name":"stdout","text":["Epochs: 4 | Train Loss:  0.066             | Train Accuracy:  0.968             | Val Loss:  0.170             | Val Accuracy:  0.882\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 680/680 [01:32<00:00,  7.38it/s]\n"]},{"output_type":"stream","name":"stdout","text":["Epochs: 5 | Train Loss:  0.053             | Train Accuracy:  0.974             | Val Loss:  0.142             | Val Accuracy:  0.924\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 85/85 [00:03<00:00, 23.87it/s]\n"]},{"output_type":"stream","name":"stdout","text":["\n","Validation Accuracy of 0.9235294117647059\n","256 0.0001 16\n"]},{"output_type":"stream","name":"stderr","text":["Some weights of the model checkpoint at bert-base-cased were not used when initializing BertModel: ['cls.seq_relationship.weight', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.dense.weight', 'cls.seq_relationship.bias', 'cls.predictions.decoder.weight', 'cls.predictions.bias', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.transform.dense.bias']\n","- This IS expected if you are initializing BertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n","- This IS NOT expected if you are initializing BertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"]},{"output_type":"stream","name":"stdout","text":["Using Cuda: True\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 680/680 [01:32<00:00,  7.38it/s]\n"]},{"output_type":"stream","name":"stdout","text":["Epochs: 1 | Train Loss:  0.509             | Train Accuracy:  0.452             | Val Loss:  0.568             | Val Accuracy:  0.394\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 680/680 [01:32<00:00,  7.38it/s]\n"]},{"output_type":"stream","name":"stdout","text":["Epochs: 2 | Train Loss:  0.547             | Train Accuracy:  0.399             | Val Loss:  0.550             | Val Accuracy:  0.376\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 680/680 [01:32<00:00,  7.38it/s]\n"]},{"output_type":"stream","name":"stdout","text":["Epochs: 3 | Train Loss:  0.549             | Train Accuracy:  0.403             | Val Loss:  0.549             | Val Accuracy:  0.388\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 680/680 [01:32<00:00,  7.35it/s]\n"]},{"output_type":"stream","name":"stdout","text":["Epochs: 4 | Train Loss:  0.549             | Train Accuracy:  0.404             | Val Loss:  0.549             | Val Accuracy:  0.388\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 680/680 [01:32<00:00,  7.35it/s]\n"]},{"output_type":"stream","name":"stdout","text":["Epochs: 5 | Train Loss:  0.549             | Train Accuracy:  0.404             | Val Loss:  0.549             | Val Accuracy:  0.388\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 11/11 [00:03<00:00,  3.53it/s]\n"]},{"output_type":"stream","name":"stdout","text":["\n","Validation Accuracy of 0.38823529411764707\n","256 0.0001 8\n"]},{"output_type":"stream","name":"stderr","text":["Some weights of the model checkpoint at bert-base-cased were not used when initializing BertModel: ['cls.seq_relationship.weight', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.dense.weight', 'cls.seq_relationship.bias', 'cls.predictions.decoder.weight', 'cls.predictions.bias', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.transform.dense.bias']\n","- This IS expected if you are initializing BertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n","- This IS NOT expected if you are initializing BertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"]},{"output_type":"stream","name":"stdout","text":["Using Cuda: True\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 680/680 [01:32<00:00,  7.38it/s]\n"]},{"output_type":"stream","name":"stdout","text":["Epochs: 1 | Train Loss:  0.549             | Train Accuracy:  0.401             | Val Loss:  0.549             | Val Accuracy:  0.394\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 680/680 [01:32<00:00,  7.35it/s]\n"]},{"output_type":"stream","name":"stdout","text":["Epochs: 2 | Train Loss:  0.549             | Train Accuracy:  0.404             | Val Loss:  0.549             | Val Accuracy:  0.388\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 680/680 [01:32<00:00,  7.36it/s]\n"]},{"output_type":"stream","name":"stdout","text":["Epochs: 3 | Train Loss:  0.549             | Train Accuracy:  0.404             | Val Loss:  0.549             | Val Accuracy:  0.388\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 680/680 [01:32<00:00,  7.36it/s]\n"]},{"output_type":"stream","name":"stdout","text":["Epochs: 4 | Train Loss:  0.550             | Train Accuracy:  0.410             | Val Loss:  0.549             | Val Accuracy:  0.388\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 680/680 [01:32<00:00,  7.37it/s]\n"]},{"output_type":"stream","name":"stdout","text":["Epochs: 5 | Train Loss:  0.549             | Train Accuracy:  0.404             | Val Loss:  0.549             | Val Accuracy:  0.388\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 22/22 [00:03<00:00,  6.83it/s]\n"]},{"output_type":"stream","name":"stdout","text":["\n","Validation Accuracy of 0.38823529411764707\n","256 0.0001 4\n"]},{"output_type":"stream","name":"stderr","text":["Some weights of the model checkpoint at bert-base-cased were not used when initializing BertModel: ['cls.seq_relationship.weight', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.dense.weight', 'cls.seq_relationship.bias', 'cls.predictions.decoder.weight', 'cls.predictions.bias', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.transform.dense.bias']\n","- This IS expected if you are initializing BertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n","- This IS NOT expected if you are initializing BertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"]},{"output_type":"stream","name":"stdout","text":["Using Cuda: True\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 680/680 [01:32<00:00,  7.38it/s]\n"]},{"output_type":"stream","name":"stdout","text":["Epochs: 1 | Train Loss:  0.502             | Train Accuracy:  0.443             | Val Loss:  0.506             | Val Accuracy:  0.459\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 680/680 [01:32<00:00,  7.36it/s]\n"]},{"output_type":"stream","name":"stdout","text":["Epochs: 2 | Train Loss:  0.484             | Train Accuracy:  0.457             | Val Loss:  0.517             | Val Accuracy:  0.435\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 680/680 [01:32<00:00,  7.38it/s]\n"]},{"output_type":"stream","name":"stdout","text":["Epochs: 3 | Train Loss:  0.481             | Train Accuracy:  0.482             | Val Loss:  0.526             | Val Accuracy:  0.435\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 680/680 [01:32<00:00,  7.38it/s]\n"]},{"output_type":"stream","name":"stdout","text":["Epochs: 4 | Train Loss:  0.485             | Train Accuracy:  0.457             | Val Loss:  0.506             | Val Accuracy:  0.453\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 680/680 [01:32<00:00,  7.38it/s]\n"]},{"output_type":"stream","name":"stdout","text":["Epochs: 5 | Train Loss:  0.481             | Train Accuracy:  0.456             | Val Loss:  0.524             | Val Accuracy:  0.447\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 43/43 [00:03<00:00, 12.94it/s]\n"]},{"output_type":"stream","name":"stdout","text":["\n","Validation Accuracy of 0.4411764705882353\n","256 0.0001 2\n"]},{"output_type":"stream","name":"stderr","text":["Some weights of the model checkpoint at bert-base-cased were not used when initializing BertModel: ['cls.seq_relationship.weight', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.dense.weight', 'cls.seq_relationship.bias', 'cls.predictions.decoder.weight', 'cls.predictions.bias', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.transform.dense.bias']\n","- This IS expected if you are initializing BertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n","- This IS NOT expected if you are initializing BertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"]},{"output_type":"stream","name":"stdout","text":["Using Cuda: True\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 680/680 [01:32<00:00,  7.38it/s]\n"]},{"output_type":"stream","name":"stdout","text":["Epochs: 1 | Train Loss:  0.494             | Train Accuracy:  0.459             | Val Loss:  0.533             | Val Accuracy:  0.418\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 680/680 [01:32<00:00,  7.38it/s]\n"]},{"output_type":"stream","name":"stdout","text":["Epochs: 2 | Train Loss:  0.516             | Train Accuracy:  0.424             | Val Loss:  0.549             | Val Accuracy:  0.388\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 680/680 [01:32<00:00,  7.38it/s]\n"]},{"output_type":"stream","name":"stdout","text":["Epochs: 3 | Train Loss:  0.549             | Train Accuracy:  0.403             | Val Loss:  0.549             | Val Accuracy:  0.388\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 680/680 [01:32<00:00,  7.38it/s]\n"]},{"output_type":"stream","name":"stdout","text":["Epochs: 4 | Train Loss:  0.549             | Train Accuracy:  0.404             | Val Loss:  0.549             | Val Accuracy:  0.388\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 680/680 [01:32<00:00,  7.35it/s]\n"]},{"output_type":"stream","name":"stdout","text":["Epochs: 5 | Train Loss:  0.549             | Train Accuracy:  0.404             | Val Loss:  0.549             | Val Accuracy:  0.388\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 85/85 [00:03<00:00, 23.81it/s]\n"]},{"output_type":"stream","name":"stdout","text":["\n","Validation Accuracy of 0.38823529411764707\n","512 1e-06 16\n"]},{"output_type":"stream","name":"stderr","text":["Some weights of the model checkpoint at bert-base-cased were not used when initializing BertModel: ['cls.seq_relationship.weight', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.dense.weight', 'cls.seq_relationship.bias', 'cls.predictions.decoder.weight', 'cls.predictions.bias', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.transform.dense.bias']\n","- This IS expected if you are initializing BertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n","- This IS NOT expected if you are initializing BertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"]},{"output_type":"stream","name":"stdout","text":["Using Cuda: True\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 680/680 [01:32<00:00,  7.37it/s]\n"]},{"output_type":"stream","name":"stdout","text":["Epochs: 1 | Train Loss:  0.526             | Train Accuracy:  0.452             | Val Loss:  0.518             | Val Accuracy:  0.465\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 680/680 [01:32<00:00,  7.38it/s]\n"]},{"output_type":"stream","name":"stdout","text":["Epochs: 2 | Train Loss:  0.460             | Train Accuracy:  0.643             | Val Loss:  0.434             | Val Accuracy:  0.676\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 680/680 [01:32<00:00,  7.38it/s]\n"]},{"output_type":"stream","name":"stdout","text":["Epochs: 3 | Train Loss:  0.345             | Train Accuracy:  0.818             | Val Loss:  0.333             | Val Accuracy:  0.829\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 680/680 [01:32<00:00,  7.38it/s]\n"]},{"output_type":"stream","name":"stdout","text":["Epochs: 4 | Train Loss:  0.259             | Train Accuracy:  0.890             | Val Loss:  0.317             | Val Accuracy:  0.776\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 680/680 [01:32<00:00,  7.37it/s]\n"]},{"output_type":"stream","name":"stdout","text":["Epochs: 5 | Train Loss:  0.181             | Train Accuracy:  0.940             | Val Loss:  0.237             | Val Accuracy:  0.859\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 11/11 [00:03<00:00,  3.51it/s]\n"]},{"output_type":"stream","name":"stdout","text":["\n","Validation Accuracy of 0.8529411764705882\n","512 1e-06 8\n"]},{"output_type":"stream","name":"stderr","text":["Some weights of the model checkpoint at bert-base-cased were not used when initializing BertModel: ['cls.seq_relationship.weight', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.dense.weight', 'cls.seq_relationship.bias', 'cls.predictions.decoder.weight', 'cls.predictions.bias', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.transform.dense.bias']\n","- This IS expected if you are initializing BertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n","- This IS NOT expected if you are initializing BertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"]},{"output_type":"stream","name":"stdout","text":["Using Cuda: True\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 680/680 [01:32<00:00,  7.38it/s]\n"]},{"output_type":"stream","name":"stdout","text":["Epochs: 1 | Train Loss:  0.542             | Train Accuracy:  0.408             | Val Loss:  0.524             | Val Accuracy:  0.447\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 680/680 [01:32<00:00,  7.37it/s]\n"]},{"output_type":"stream","name":"stdout","text":["Epochs: 2 | Train Loss:  0.525             | Train Accuracy:  0.459             | Val Loss:  0.522             | Val Accuracy:  0.459\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 680/680 [01:32<00:00,  7.37it/s]\n"]},{"output_type":"stream","name":"stdout","text":["Epochs: 3 | Train Loss:  0.503             | Train Accuracy:  0.512             | Val Loss:  0.488             | Val Accuracy:  0.541\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 680/680 [01:32<00:00,  7.38it/s]\n"]},{"output_type":"stream","name":"stdout","text":["Epochs: 4 | Train Loss:  0.430             | Train Accuracy:  0.699             | Val Loss:  0.402             | Val Accuracy:  0.735\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 680/680 [01:32<00:00,  7.38it/s]\n"]},{"output_type":"stream","name":"stdout","text":["Epochs: 5 | Train Loss:  0.313             | Train Accuracy:  0.905             | Val Loss:  0.310             | Val Accuracy:  0.859\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 22/22 [00:03<00:00,  6.81it/s]\n"]},{"output_type":"stream","name":"stdout","text":["\n","Validation Accuracy of 0.8764705882352941\n","512 1e-06 4\n"]},{"output_type":"stream","name":"stderr","text":["Some weights of the model checkpoint at bert-base-cased were not used when initializing BertModel: ['cls.seq_relationship.weight', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.dense.weight', 'cls.seq_relationship.bias', 'cls.predictions.decoder.weight', 'cls.predictions.bias', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.transform.dense.bias']\n","- This IS expected if you are initializing BertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n","- This IS NOT expected if you are initializing BertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"]},{"output_type":"stream","name":"stdout","text":["Using Cuda: True\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 680/680 [01:32<00:00,  7.37it/s]\n"]},{"output_type":"stream","name":"stdout","text":["Epochs: 1 | Train Loss:  0.533             | Train Accuracy:  0.429             | Val Loss:  0.519             | Val Accuracy:  0.506\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 680/680 [01:32<00:00,  7.38it/s]\n"]},{"output_type":"stream","name":"stdout","text":["Epochs: 2 | Train Loss:  0.490             | Train Accuracy:  0.583             | Val Loss:  0.488             | Val Accuracy:  0.541\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 680/680 [01:32<00:00,  7.38it/s]\n"]},{"output_type":"stream","name":"stdout","text":["Epochs: 3 | Train Loss:  0.418             | Train Accuracy:  0.715             | Val Loss:  0.403             | Val Accuracy:  0.741\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 680/680 [01:32<00:00,  7.37it/s]\n"]},{"output_type":"stream","name":"stdout","text":["Epochs: 4 | Train Loss:  0.338             | Train Accuracy:  0.805             | Val Loss:  0.352             | Val Accuracy:  0.765\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 680/680 [01:32<00:00,  7.37it/s]\n"]},{"output_type":"stream","name":"stdout","text":["Epochs: 5 | Train Loss:  0.255             | Train Accuracy:  0.895             | Val Loss:  0.289             | Val Accuracy:  0.835\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 43/43 [00:03<00:00, 12.99it/s]\n"]},{"output_type":"stream","name":"stdout","text":["\n","Validation Accuracy of 0.8411764705882353\n","512 1e-06 2\n"]},{"output_type":"stream","name":"stderr","text":["Some weights of the model checkpoint at bert-base-cased were not used when initializing BertModel: ['cls.seq_relationship.weight', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.dense.weight', 'cls.seq_relationship.bias', 'cls.predictions.decoder.weight', 'cls.predictions.bias', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.transform.dense.bias']\n","- This IS expected if you are initializing BertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n","- This IS NOT expected if you are initializing BertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"]},{"output_type":"stream","name":"stdout","text":["Using Cuda: True\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 680/680 [01:32<00:00,  7.37it/s]\n"]},{"output_type":"stream","name":"stdout","text":["Epochs: 1 | Train Loss:  0.529             | Train Accuracy:  0.476             | Val Loss:  0.507             | Val Accuracy:  0.582\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 680/680 [01:32<00:00,  7.37it/s]\n"]},{"output_type":"stream","name":"stdout","text":["Epochs: 2 | Train Loss:  0.470             | Train Accuracy:  0.654             | Val Loss:  0.449             | Val Accuracy:  0.647\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 680/680 [01:32<00:00,  7.36it/s]\n"]},{"output_type":"stream","name":"stdout","text":["Epochs: 3 | Train Loss:  0.379             | Train Accuracy:  0.776             | Val Loss:  0.398             | Val Accuracy:  0.712\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 680/680 [01:32<00:00,  7.37it/s]\n"]},{"output_type":"stream","name":"stdout","text":["Epochs: 4 | Train Loss:  0.296             | Train Accuracy:  0.872             | Val Loss:  0.322             | Val Accuracy:  0.806\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 680/680 [01:32<00:00,  7.37it/s]\n"]},{"output_type":"stream","name":"stdout","text":["Epochs: 5 | Train Loss:  0.224             | Train Accuracy:  0.937             | Val Loss:  0.262             | Val Accuracy:  0.859\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 85/85 [00:03<00:00, 23.88it/s]\n"]},{"output_type":"stream","name":"stdout","text":["\n","Validation Accuracy of 0.8647058823529412\n","512 1e-05 16\n"]},{"output_type":"stream","name":"stderr","text":["Some weights of the model checkpoint at bert-base-cased were not used when initializing BertModel: ['cls.seq_relationship.weight', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.dense.weight', 'cls.seq_relationship.bias', 'cls.predictions.decoder.weight', 'cls.predictions.bias', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.transform.dense.bias']\n","- This IS expected if you are initializing BertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n","- This IS NOT expected if you are initializing BertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"]},{"output_type":"stream","name":"stdout","text":["Using Cuda: True\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 680/680 [01:32<00:00,  7.37it/s]\n"]},{"output_type":"stream","name":"stdout","text":["Epochs: 1 | Train Loss:  0.460             | Train Accuracy:  0.519             | Val Loss:  0.399             | Val Accuracy:  0.706\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 680/680 [01:32<00:00,  7.37it/s]\n"]},{"output_type":"stream","name":"stdout","text":["Epochs: 2 | Train Loss:  0.261             | Train Accuracy:  0.796             | Val Loss:  0.280             | Val Accuracy:  0.735\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 680/680 [01:32<00:00,  7.37it/s]\n"]},{"output_type":"stream","name":"stdout","text":["Epochs: 3 | Train Loss:  0.118             | Train Accuracy:  0.929             | Val Loss:  0.164             | Val Accuracy:  0.888\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 680/680 [01:32<00:00,  7.37it/s]\n"]},{"output_type":"stream","name":"stdout","text":["Epochs: 4 | Train Loss:  0.051             | Train Accuracy:  0.971             | Val Loss:  0.190             | Val Accuracy:  0.882\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 680/680 [01:32<00:00,  7.38it/s]\n"]},{"output_type":"stream","name":"stdout","text":["Epochs: 5 | Train Loss:  0.038             | Train Accuracy:  0.982             | Val Loss:  0.290             | Val Accuracy:  0.865\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 11/11 [00:03<00:00,  3.52it/s]\n"]},{"output_type":"stream","name":"stdout","text":["\n","Validation Accuracy of 0.8647058823529412\n","512 1e-05 8\n"]},{"output_type":"stream","name":"stderr","text":["Some weights of the model checkpoint at bert-base-cased were not used when initializing BertModel: ['cls.seq_relationship.weight', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.dense.weight', 'cls.seq_relationship.bias', 'cls.predictions.decoder.weight', 'cls.predictions.bias', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.transform.dense.bias']\n","- This IS expected if you are initializing BertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n","- This IS NOT expected if you are initializing BertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"]},{"output_type":"stream","name":"stdout","text":["Using Cuda: True\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 680/680 [01:32<00:00,  7.38it/s]\n"]},{"output_type":"stream","name":"stdout","text":["Epochs: 1 | Train Loss:  0.471             | Train Accuracy:  0.586             | Val Loss:  0.353             | Val Accuracy:  0.747\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 680/680 [01:32<00:00,  7.38it/s]\n"]},{"output_type":"stream","name":"stdout","text":["Epochs: 2 | Train Loss:  0.213             | Train Accuracy:  0.874             | Val Loss:  0.215             | Val Accuracy:  0.865\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 680/680 [01:32<00:00,  7.37it/s]\n"]},{"output_type":"stream","name":"stdout","text":["Epochs: 3 | Train Loss:  0.111             | Train Accuracy:  0.936             | Val Loss:  0.179             | Val Accuracy:  0.847\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 680/680 [01:32<00:00,  7.37it/s]\n"]},{"output_type":"stream","name":"stdout","text":["Epochs: 4 | Train Loss:  0.055             | Train Accuracy:  0.974             | Val Loss:  0.122             | Val Accuracy:  0.929\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 680/680 [01:32<00:00,  7.36it/s]\n"]},{"output_type":"stream","name":"stdout","text":["Epochs: 5 | Train Loss:  0.033             | Train Accuracy:  0.986             | Val Loss:  0.129             | Val Accuracy:  0.924\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 22/22 [00:03<00:00,  6.80it/s]\n"]},{"output_type":"stream","name":"stdout","text":["\n","Validation Accuracy of 0.9235294117647059\n","512 1e-05 4\n"]},{"output_type":"stream","name":"stderr","text":["Some weights of the model checkpoint at bert-base-cased were not used when initializing BertModel: ['cls.seq_relationship.weight', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.dense.weight', 'cls.seq_relationship.bias', 'cls.predictions.decoder.weight', 'cls.predictions.bias', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.transform.dense.bias']\n","- This IS expected if you are initializing BertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n","- This IS NOT expected if you are initializing BertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"]},{"output_type":"stream","name":"stdout","text":["Using Cuda: True\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 680/680 [01:32<00:00,  7.36it/s]\n"]},{"output_type":"stream","name":"stdout","text":["Epochs: 1 | Train Loss:  0.514             | Train Accuracy:  0.461             | Val Loss:  0.459             | Val Accuracy:  0.529\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 680/680 [01:32<00:00,  7.36it/s]\n"]},{"output_type":"stream","name":"stdout","text":["Epochs: 2 | Train Loss:  0.319             | Train Accuracy:  0.715             | Val Loss:  0.227             | Val Accuracy:  0.847\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 680/680 [01:32<00:00,  7.36it/s]\n"]},{"output_type":"stream","name":"stdout","text":["Epochs: 3 | Train Loss:  0.121             | Train Accuracy:  0.929             | Val Loss:  0.175             | Val Accuracy:  0.859\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 680/680 [01:32<00:00,  7.36it/s]\n"]},{"output_type":"stream","name":"stdout","text":["Epochs: 4 | Train Loss:  0.061             | Train Accuracy:  0.970             | Val Loss:  0.203             | Val Accuracy:  0.871\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 680/680 [01:32<00:00,  7.36it/s]\n"]},{"output_type":"stream","name":"stdout","text":["Epochs: 5 | Train Loss:  0.047             | Train Accuracy:  0.971             | Val Loss:  0.204             | Val Accuracy:  0.882\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 43/43 [00:03<00:00, 12.92it/s]\n"]},{"output_type":"stream","name":"stdout","text":["\n","Validation Accuracy of 0.8823529411764706\n","512 1e-05 2\n"]},{"output_type":"stream","name":"stderr","text":["Some weights of the model checkpoint at bert-base-cased were not used when initializing BertModel: ['cls.seq_relationship.weight', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.dense.weight', 'cls.seq_relationship.bias', 'cls.predictions.decoder.weight', 'cls.predictions.bias', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.transform.dense.bias']\n","- This IS expected if you are initializing BertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n","- This IS NOT expected if you are initializing BertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"]},{"output_type":"stream","name":"stdout","text":["Using Cuda: True\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 680/680 [01:32<00:00,  7.35it/s]\n"]},{"output_type":"stream","name":"stdout","text":["Epochs: 1 | Train Loss:  0.420             | Train Accuracy:  0.626             | Val Loss:  0.331             | Val Accuracy:  0.806\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 680/680 [01:32<00:00,  7.37it/s]\n"]},{"output_type":"stream","name":"stdout","text":["Epochs: 2 | Train Loss:  0.202             | Train Accuracy:  0.885             | Val Loss:  0.237             | Val Accuracy:  0.847\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 680/680 [01:32<00:00,  7.38it/s]\n"]},{"output_type":"stream","name":"stdout","text":["Epochs: 3 | Train Loss:  0.092             | Train Accuracy:  0.954             | Val Loss:  0.182             | Val Accuracy:  0.882\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 680/680 [01:32<00:00,  7.38it/s]\n"]},{"output_type":"stream","name":"stdout","text":["Epochs: 4 | Train Loss:  0.038             | Train Accuracy:  0.985             | Val Loss:  0.120             | Val Accuracy:  0.929\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 680/680 [01:32<00:00,  7.38it/s]\n"]},{"output_type":"stream","name":"stdout","text":["Epochs: 5 | Train Loss:  0.026             | Train Accuracy:  0.989             | Val Loss:  0.152             | Val Accuracy:  0.918\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 85/85 [00:03<00:00, 23.84it/s]\n"]},{"output_type":"stream","name":"stdout","text":["\n","Validation Accuracy of 0.9176470588235294\n","512 0.0001 16\n"]},{"output_type":"stream","name":"stderr","text":["Some weights of the model checkpoint at bert-base-cased were not used when initializing BertModel: ['cls.seq_relationship.weight', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.dense.weight', 'cls.seq_relationship.bias', 'cls.predictions.decoder.weight', 'cls.predictions.bias', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.transform.dense.bias']\n","- This IS expected if you are initializing BertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n","- This IS NOT expected if you are initializing BertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"]},{"output_type":"stream","name":"stdout","text":["Using Cuda: True\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 680/680 [01:32<00:00,  7.38it/s]\n"]},{"output_type":"stream","name":"stdout","text":["Epochs: 1 | Train Loss:  0.550             | Train Accuracy:  0.396             | Val Loss:  0.549             | Val Accuracy:  0.388\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 680/680 [01:32<00:00,  7.37it/s]\n"]},{"output_type":"stream","name":"stdout","text":["Epochs: 2 | Train Loss:  0.549             | Train Accuracy:  0.404             | Val Loss:  0.549             | Val Accuracy:  0.388\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 680/680 [01:32<00:00,  7.34it/s]\n"]},{"output_type":"stream","name":"stdout","text":["Epochs: 3 | Train Loss:  0.549             | Train Accuracy:  0.404             | Val Loss:  0.549             | Val Accuracy:  0.388\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 680/680 [01:32<00:00,  7.32it/s]\n"]},{"output_type":"stream","name":"stdout","text":["Epochs: 4 | Train Loss:  0.549             | Train Accuracy:  0.404             | Val Loss:  0.549             | Val Accuracy:  0.388\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 680/680 [01:32<00:00,  7.33it/s]\n"]},{"output_type":"stream","name":"stdout","text":["Epochs: 5 | Train Loss:  0.549             | Train Accuracy:  0.404             | Val Loss:  0.549             | Val Accuracy:  0.388\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 11/11 [00:03<00:00,  3.52it/s]\n"]},{"output_type":"stream","name":"stdout","text":["\n","Validation Accuracy of 0.38823529411764707\n","512 0.0001 8\n"]},{"output_type":"stream","name":"stderr","text":["Some weights of the model checkpoint at bert-base-cased were not used when initializing BertModel: ['cls.seq_relationship.weight', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.dense.weight', 'cls.seq_relationship.bias', 'cls.predictions.decoder.weight', 'cls.predictions.bias', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.transform.dense.bias']\n","- This IS expected if you are initializing BertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n","- This IS NOT expected if you are initializing BertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"]},{"output_type":"stream","name":"stdout","text":["Using Cuda: True\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 680/680 [01:32<00:00,  7.36it/s]\n"]},{"output_type":"stream","name":"stdout","text":["Epochs: 1 | Train Loss:  0.549             | Train Accuracy:  0.404             | Val Loss:  0.549             | Val Accuracy:  0.388\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 680/680 [01:32<00:00,  7.35it/s]\n"]},{"output_type":"stream","name":"stdout","text":["Epochs: 2 | Train Loss:  0.549             | Train Accuracy:  0.404             | Val Loss:  0.549             | Val Accuracy:  0.388\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 680/680 [01:32<00:00,  7.33it/s]\n"]},{"output_type":"stream","name":"stdout","text":["Epochs: 3 | Train Loss:  0.549             | Train Accuracy:  0.404             | Val Loss:  0.549             | Val Accuracy:  0.382\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 680/680 [01:32<00:00,  7.32it/s]\n"]},{"output_type":"stream","name":"stdout","text":["Epochs: 4 | Train Loss:  0.549             | Train Accuracy:  0.404             | Val Loss:  0.549             | Val Accuracy:  0.388\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 680/680 [01:32<00:00,  7.35it/s]\n"]},{"output_type":"stream","name":"stdout","text":["Epochs: 5 | Train Loss:  0.550             | Train Accuracy:  0.407             | Val Loss:  0.549             | Val Accuracy:  0.388\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 22/22 [00:03<00:00,  6.80it/s]\n"]},{"output_type":"stream","name":"stdout","text":["\n","Validation Accuracy of 0.38823529411764707\n","512 0.0001 4\n"]},{"output_type":"stream","name":"stderr","text":["Some weights of the model checkpoint at bert-base-cased were not used when initializing BertModel: ['cls.seq_relationship.weight', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.dense.weight', 'cls.seq_relationship.bias', 'cls.predictions.decoder.weight', 'cls.predictions.bias', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.transform.dense.bias']\n","- This IS expected if you are initializing BertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n","- This IS NOT expected if you are initializing BertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"]},{"output_type":"stream","name":"stdout","text":["Using Cuda: True\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 680/680 [01:32<00:00,  7.37it/s]\n"]},{"output_type":"stream","name":"stdout","text":["Epochs: 1 | Train Loss:  0.549             | Train Accuracy:  0.401             | Val Loss:  0.549             | Val Accuracy:  0.388\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 680/680 [01:32<00:00,  7.35it/s]\n"]},{"output_type":"stream","name":"stdout","text":["Epochs: 2 | Train Loss:  0.549             | Train Accuracy:  0.404             | Val Loss:  0.549             | Val Accuracy:  0.388\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 680/680 [01:32<00:00,  7.37it/s]\n"]},{"output_type":"stream","name":"stdout","text":["Epochs: 3 | Train Loss:  0.549             | Train Accuracy:  0.404             | Val Loss:  0.549             | Val Accuracy:  0.388\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 680/680 [01:32<00:00,  7.35it/s]\n"]},{"output_type":"stream","name":"stdout","text":["Epochs: 4 | Train Loss:  0.549             | Train Accuracy:  0.404             | Val Loss:  0.549             | Val Accuracy:  0.388\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 680/680 [01:32<00:00,  7.33it/s]\n"]},{"output_type":"stream","name":"stdout","text":["Epochs: 5 | Train Loss:  0.549             | Train Accuracy:  0.404             | Val Loss:  0.549             | Val Accuracy:  0.388\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 43/43 [00:03<00:00, 12.97it/s]\n"]},{"output_type":"stream","name":"stdout","text":["\n","Validation Accuracy of 0.38823529411764707\n","512 0.0001 2\n"]},{"output_type":"stream","name":"stderr","text":["Some weights of the model checkpoint at bert-base-cased were not used when initializing BertModel: ['cls.seq_relationship.weight', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.dense.weight', 'cls.seq_relationship.bias', 'cls.predictions.decoder.weight', 'cls.predictions.bias', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.transform.dense.bias']\n","- This IS expected if you are initializing BertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n","- This IS NOT expected if you are initializing BertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"]},{"output_type":"stream","name":"stdout","text":["Using Cuda: True\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 680/680 [01:32<00:00,  7.37it/s]\n"]},{"output_type":"stream","name":"stdout","text":["Epochs: 1 | Train Loss:  0.550             | Train Accuracy:  0.398             | Val Loss:  0.549             | Val Accuracy:  0.388\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 680/680 [01:32<00:00,  7.35it/s]\n"]},{"output_type":"stream","name":"stdout","text":["Epochs: 2 | Train Loss:  0.549             | Train Accuracy:  0.404             | Val Loss:  0.549             | Val Accuracy:  0.388\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 680/680 [01:32<00:00,  7.34it/s]\n"]},{"output_type":"stream","name":"stdout","text":["Epochs: 3 | Train Loss:  0.549             | Train Accuracy:  0.404             | Val Loss:  0.549             | Val Accuracy:  0.388\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 680/680 [01:32<00:00,  7.34it/s]\n"]},{"output_type":"stream","name":"stdout","text":["Epochs: 4 | Train Loss:  0.549             | Train Accuracy:  0.404             | Val Loss:  0.549             | Val Accuracy:  0.388\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 680/680 [01:32<00:00,  7.34it/s]\n"]},{"output_type":"stream","name":"stdout","text":["Epochs: 5 | Train Loss:  0.549             | Train Accuracy:  0.404             | Val Loss:  0.549             | Val Accuracy:  0.388\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 85/85 [00:03<00:00, 23.89it/s]"]},{"output_type":"stream","name":"stdout","text":["\n","Validation Accuracy of 0.38823529411764707\n","The highest accuracy achieved by the model was: 160\n","Best Hyperparameters: {'learning_rate': 1e-05, 'hidden_size': 128, 'batch_size': 8}\n"]},{"output_type":"stream","name":"stderr","text":["\n"]}],"metadata":{"id":"6JYDhOIVNCd4","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1648544041164,"user_tz":240,"elapsed":18571545,"user":{"displayName":"Vruthik Thakkar","userId":"03035406201152502707"}},"outputId":"baa84211-a461-457d-98b6-af3fa970a41f"}},{"cell_type":"code","source":["# best_validation_accuracy = 0.9411764705882353\n","\n","# 128 1e-05 4\n","# Epoch 3\n","# 0.953\n","# {'Epochs': 3, 'hidden_layer_size': 128, 'learning_rate': 1e-05, 'batch_size': 4}\n","\n"],"metadata":{"id":"wVGgxJxU_Dr4"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["# Train Model"],"metadata":{"id":"IQ5s3pmcM-la"}},{"cell_type":"code","execution_count":8,"source":["num_epochs = 3\n","learning_rate = 1e-5\n","hidden_size = 128\n","batch_size = 4\n","clf = BertClassifier(hidden_size=hidden_size)"],"outputs":[{"output_type":"stream","name":"stderr","text":["Some weights of the model checkpoint at bert-base-cased were not used when initializing BertModel: ['cls.predictions.decoder.weight', 'cls.seq_relationship.weight', 'cls.seq_relationship.bias', 'cls.predictions.bias', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.transform.dense.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.dense.weight']\n","- This IS expected if you are initializing BertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n","- This IS NOT expected if you are initializing BertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"]}],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"I1mHnjT-bw1F","executionInfo":{"status":"ok","timestamp":1648563991020,"user_tz":240,"elapsed":2123,"user":{"displayName":"Vruthik Thakkar","userId":"03035406201152502707"}},"outputId":"eb681766-8dd0-41ff-e218-0f1116c456df"}},{"cell_type":"code","execution_count":9,"source":["train(clf, df_train, df_val, learning_rate, num_epochs, batch_size=batch_size)\n","\n","torch.save(clf.state_dict(), os.path.join(GOOGLE_DRIVE_PATH, 'checkpoint_tuned.pth'))\n","\n","files.download(os.path.join(GOOGLE_DRIVE_PATH, 'checkpoint_tuned.pth'))"],"outputs":[{"output_type":"display_data","data":{"text/plain":["Downloading:   0%|          | 0.00/208k [00:00<?, ?B/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"8ced2d7a699d44a5b85d76aee4928b15"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["Downloading:   0%|          | 0.00/29.0 [00:00<?, ?B/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"2ee4c9d79ed14932a61ef9ab43a7a7c8"}},"metadata":{}},{"output_type":"stream","name":"stdout","text":["Using Cuda: True\n"]},{"output_type":"stream","name":"stderr","text":["\n","  0%|          | 0/340 [00:00<?, ?it/s]\u001b[A\n","  0%|          | 1/340 [00:00<02:56,  1.92it/s]\u001b[A\n","  1%|          | 2/340 [00:00<02:22,  2.37it/s]\u001b[A\n","  1%|          | 3/340 [00:01<02:11,  2.56it/s]\u001b[A\n","  1%|          | 4/340 [00:01<02:07,  2.63it/s]\u001b[A\n","  1%|▏         | 5/340 [00:01<02:04,  2.68it/s]\u001b[A\n","  2%|▏         | 6/340 [00:02<02:03,  2.72it/s]\u001b[A\n","  2%|▏         | 7/340 [00:02<02:01,  2.74it/s]\u001b[A\n","  2%|▏         | 8/340 [00:03<02:00,  2.76it/s]\u001b[A\n","  3%|▎         | 9/340 [00:03<01:59,  2.76it/s]\u001b[A\n","  3%|▎         | 10/340 [00:03<01:59,  2.77it/s]\u001b[A\n","  3%|▎         | 11/340 [00:04<01:57,  2.80it/s]\u001b[A\n","  4%|▎         | 12/340 [00:04<01:57,  2.78it/s]\u001b[A\n","  4%|▍         | 13/340 [00:04<01:57,  2.78it/s]\u001b[A\n","  4%|▍         | 14/340 [00:05<01:56,  2.80it/s]\u001b[A\n","  4%|▍         | 15/340 [00:05<01:56,  2.80it/s]\u001b[A\n","  5%|▍         | 16/340 [00:05<01:55,  2.80it/s]\u001b[A\n","  5%|▌         | 17/340 [00:06<01:55,  2.80it/s]\u001b[A\n","  5%|▌         | 18/340 [00:06<01:55,  2.79it/s]\u001b[A\n","  6%|▌         | 19/340 [00:06<01:54,  2.79it/s]\u001b[A\n","  6%|▌         | 20/340 [00:07<01:54,  2.81it/s]\u001b[A\n","  6%|▌         | 21/340 [00:07<01:54,  2.79it/s]\u001b[A\n","  6%|▋         | 22/340 [00:08<01:54,  2.79it/s]\u001b[A\n","  7%|▋         | 23/340 [00:08<01:52,  2.81it/s]\u001b[A\n","  7%|▋         | 24/340 [00:08<01:53,  2.79it/s]\u001b[A\n","  7%|▋         | 25/340 [00:09<01:53,  2.78it/s]\u001b[A\n","  8%|▊         | 26/340 [00:09<01:53,  2.76it/s]\u001b[A\n","  8%|▊         | 27/340 [00:09<01:53,  2.75it/s]\u001b[A\n","  8%|▊         | 28/340 [00:10<01:53,  2.75it/s]\u001b[A\n","  9%|▊         | 29/340 [00:10<01:53,  2.75it/s]\u001b[A\n","  9%|▉         | 30/340 [00:10<01:52,  2.75it/s]\u001b[A\n","  9%|▉         | 31/340 [00:11<01:51,  2.76it/s]\u001b[A\n","  9%|▉         | 32/340 [00:11<01:51,  2.76it/s]\u001b[A\n"," 10%|▉         | 33/340 [00:12<01:51,  2.75it/s]\u001b[A\n"," 10%|█         | 34/340 [00:12<01:51,  2.75it/s]\u001b[A\n"," 10%|█         | 35/340 [00:12<01:50,  2.76it/s]\u001b[A\n"," 11%|█         | 36/340 [00:13<01:48,  2.79it/s]\u001b[A\n"," 11%|█         | 37/340 [00:13<01:48,  2.80it/s]\u001b[A\n"," 11%|█         | 38/340 [00:13<01:48,  2.80it/s]\u001b[A\n"," 11%|█▏        | 39/340 [00:14<01:47,  2.79it/s]\u001b[A\n"," 12%|█▏        | 40/340 [00:14<01:47,  2.80it/s]\u001b[A\n"," 12%|█▏        | 41/340 [00:14<01:47,  2.78it/s]\u001b[A\n"," 12%|█▏        | 42/340 [00:15<01:47,  2.77it/s]\u001b[A\n"," 13%|█▎        | 43/340 [00:15<01:47,  2.76it/s]\u001b[A\n"," 13%|█▎        | 44/340 [00:15<01:48,  2.74it/s]\u001b[A\n"," 13%|█▎        | 45/340 [00:16<01:47,  2.74it/s]\u001b[A\n"," 14%|█▎        | 46/340 [00:16<01:48,  2.70it/s]\u001b[A\n"," 14%|█▍        | 47/340 [00:17<01:48,  2.71it/s]\u001b[A\n"," 14%|█▍        | 48/340 [00:17<01:47,  2.72it/s]\u001b[A\n"," 14%|█▍        | 49/340 [00:17<01:47,  2.72it/s]\u001b[A\n"," 15%|█▍        | 50/340 [00:18<01:46,  2.73it/s]\u001b[A\n"," 15%|█▌        | 51/340 [00:18<01:45,  2.74it/s]\u001b[A\n"," 15%|█▌        | 52/340 [00:18<01:44,  2.75it/s]\u001b[A\n"," 16%|█▌        | 53/340 [00:19<01:44,  2.75it/s]\u001b[A\n"," 16%|█▌        | 54/340 [00:19<01:45,  2.72it/s]\u001b[A\n"," 16%|█▌        | 55/340 [00:20<01:44,  2.73it/s]\u001b[A\n"," 16%|█▋        | 56/340 [00:20<01:43,  2.74it/s]\u001b[A\n"," 17%|█▋        | 57/340 [00:20<01:42,  2.75it/s]\u001b[A\n"," 17%|█▋        | 58/340 [00:21<01:43,  2.74it/s]\u001b[A\n"," 17%|█▋        | 59/340 [00:21<01:43,  2.73it/s]\u001b[A\n"," 18%|█▊        | 60/340 [00:21<01:41,  2.75it/s]\u001b[A\n"," 18%|█▊        | 61/340 [00:22<01:41,  2.75it/s]\u001b[A\n"," 18%|█▊        | 62/340 [00:22<01:42,  2.70it/s]\u001b[A\n"," 19%|█▊        | 63/340 [00:22<01:42,  2.71it/s]\u001b[A\n"," 19%|█▉        | 64/340 [00:23<01:41,  2.73it/s]\u001b[A\n"," 19%|█▉        | 65/340 [00:23<01:41,  2.70it/s]\u001b[A\n"," 19%|█▉        | 66/340 [00:24<01:40,  2.71it/s]\u001b[A\n"," 20%|█▉        | 67/340 [00:24<01:41,  2.69it/s]\u001b[A\n"," 20%|██        | 68/340 [00:24<01:40,  2.70it/s]\u001b[A\n"," 20%|██        | 69/340 [00:25<01:40,  2.68it/s]\u001b[A\n"," 21%|██        | 70/340 [00:25<01:40,  2.69it/s]\u001b[A\n"," 21%|██        | 71/340 [00:25<01:39,  2.70it/s]\u001b[A\n"," 21%|██        | 72/340 [00:26<01:39,  2.69it/s]\u001b[A\n"," 21%|██▏       | 73/340 [00:26<01:38,  2.70it/s]\u001b[A\n"," 22%|██▏       | 74/340 [00:27<01:38,  2.71it/s]\u001b[A\n"," 22%|██▏       | 75/340 [00:27<01:37,  2.71it/s]\u001b[A\n"," 22%|██▏       | 76/340 [00:27<01:37,  2.71it/s]\u001b[A\n"," 23%|██▎       | 77/340 [00:28<01:36,  2.72it/s]\u001b[A\n"," 23%|██▎       | 78/340 [00:28<01:36,  2.70it/s]\u001b[A\n"," 23%|██▎       | 79/340 [00:28<01:37,  2.66it/s]\u001b[A\n"," 24%|██▎       | 80/340 [00:29<01:37,  2.66it/s]\u001b[A\n"," 24%|██▍       | 81/340 [00:29<01:36,  2.67it/s]\u001b[A\n"," 24%|██▍       | 82/340 [00:30<01:36,  2.68it/s]\u001b[A\n"," 24%|██▍       | 83/340 [00:30<01:35,  2.69it/s]\u001b[A\n"," 25%|██▍       | 84/340 [00:30<01:34,  2.72it/s]\u001b[A\n"," 25%|██▌       | 85/340 [00:31<01:33,  2.72it/s]\u001b[A\n"," 25%|██▌       | 86/340 [00:31<01:33,  2.72it/s]\u001b[A\n"," 26%|██▌       | 87/340 [00:31<01:32,  2.72it/s]\u001b[A\n"," 26%|██▌       | 88/340 [00:32<01:32,  2.72it/s]\u001b[A\n"," 26%|██▌       | 89/340 [00:32<01:32,  2.73it/s]\u001b[A\n"," 26%|██▋       | 90/340 [00:32<01:31,  2.73it/s]\u001b[A\n"," 27%|██▋       | 91/340 [00:33<01:31,  2.72it/s]\u001b[A\n"," 27%|██▋       | 92/340 [00:33<01:30,  2.73it/s]\u001b[A\n"," 27%|██▋       | 93/340 [00:34<01:29,  2.76it/s]\u001b[A\n"," 28%|██▊       | 94/340 [00:34<01:29,  2.74it/s]\u001b[A\n"," 28%|██▊       | 95/340 [00:34<01:29,  2.73it/s]\u001b[A\n"," 28%|██▊       | 96/340 [00:35<01:29,  2.73it/s]\u001b[A\n"," 29%|██▊       | 97/340 [00:35<01:29,  2.71it/s]\u001b[A\n"," 29%|██▉       | 98/340 [00:35<01:28,  2.72it/s]\u001b[A\n"," 29%|██▉       | 99/340 [00:36<01:28,  2.72it/s]\u001b[A\n"," 29%|██▉       | 100/340 [00:36<01:27,  2.73it/s]\u001b[A\n"," 30%|██▉       | 101/340 [00:36<01:27,  2.72it/s]\u001b[A\n"," 30%|███       | 102/340 [00:37<01:27,  2.71it/s]\u001b[A\n"," 30%|███       | 103/340 [00:37<01:27,  2.71it/s]\u001b[A\n"," 31%|███       | 104/340 [00:38<01:27,  2.71it/s]\u001b[A\n"," 31%|███       | 105/340 [00:38<01:26,  2.72it/s]\u001b[A\n"," 31%|███       | 106/340 [00:38<01:26,  2.72it/s]\u001b[A\n"," 31%|███▏      | 107/340 [00:39<01:25,  2.73it/s]\u001b[A\n"," 32%|███▏      | 108/340 [00:39<01:25,  2.72it/s]\u001b[A\n"," 32%|███▏      | 109/340 [00:39<01:24,  2.72it/s]\u001b[A\n"," 32%|███▏      | 110/340 [00:40<01:24,  2.73it/s]\u001b[A\n"," 33%|███▎      | 111/340 [00:40<01:23,  2.73it/s]\u001b[A\n"," 33%|███▎      | 112/340 [00:41<01:23,  2.72it/s]\u001b[A\n"," 33%|███▎      | 113/340 [00:41<01:23,  2.73it/s]\u001b[A\n"," 34%|███▎      | 114/340 [00:41<01:22,  2.73it/s]\u001b[A\n"," 34%|███▍      | 115/340 [00:42<01:22,  2.72it/s]\u001b[A\n"," 34%|███▍      | 116/340 [00:42<01:22,  2.71it/s]\u001b[A\n"," 34%|███▍      | 117/340 [00:42<01:22,  2.70it/s]\u001b[A\n"," 35%|███▍      | 118/340 [00:43<01:22,  2.71it/s]\u001b[A\n"," 35%|███▌      | 119/340 [00:43<01:21,  2.70it/s]\u001b[A\n"," 35%|███▌      | 120/340 [00:43<01:21,  2.69it/s]\u001b[A\n"," 36%|███▌      | 121/340 [00:44<01:21,  2.69it/s]\u001b[A\n"," 36%|███▌      | 122/340 [00:44<01:21,  2.68it/s]\u001b[A\n"," 36%|███▌      | 123/340 [00:45<01:20,  2.68it/s]\u001b[A\n"," 36%|███▋      | 124/340 [00:45<01:20,  2.67it/s]\u001b[A\n"," 37%|███▋      | 125/340 [00:45<01:20,  2.67it/s]\u001b[A\n"," 37%|███▋      | 126/340 [00:46<01:19,  2.69it/s]\u001b[A\n"," 37%|███▋      | 127/340 [00:46<01:19,  2.68it/s]\u001b[A\n"," 38%|███▊      | 128/340 [00:46<01:18,  2.69it/s]\u001b[A\n"," 38%|███▊      | 129/340 [00:47<01:18,  2.70it/s]\u001b[A\n"," 38%|███▊      | 130/340 [00:47<01:17,  2.70it/s]\u001b[A\n"," 39%|███▊      | 131/340 [00:48<01:17,  2.69it/s]\u001b[A\n"," 39%|███▉      | 132/340 [00:48<01:16,  2.70it/s]\u001b[A\n"," 39%|███▉      | 133/340 [00:48<01:16,  2.69it/s]\u001b[A\n"," 39%|███▉      | 134/340 [00:49<01:16,  2.70it/s]\u001b[A\n"," 40%|███▉      | 135/340 [00:49<01:16,  2.69it/s]\u001b[A\n"," 40%|████      | 136/340 [00:49<01:15,  2.69it/s]\u001b[A\n"," 40%|████      | 137/340 [00:50<01:15,  2.69it/s]\u001b[A\n"," 41%|████      | 138/340 [00:50<01:15,  2.69it/s]\u001b[A\n"," 41%|████      | 139/340 [00:51<01:14,  2.69it/s]\u001b[A\n"," 41%|████      | 140/340 [00:51<01:14,  2.69it/s]\u001b[A\n"," 41%|████▏     | 141/340 [00:51<01:13,  2.71it/s]\u001b[A\n"," 42%|████▏     | 142/340 [00:52<01:13,  2.70it/s]\u001b[A\n"," 42%|████▏     | 143/340 [00:52<01:13,  2.69it/s]\u001b[A\n"," 42%|████▏     | 144/340 [00:52<01:13,  2.68it/s]\u001b[A\n"," 43%|████▎     | 145/340 [00:53<01:12,  2.69it/s]\u001b[A\n"," 43%|████▎     | 146/340 [00:53<01:12,  2.68it/s]\u001b[A\n"," 43%|████▎     | 147/340 [00:54<01:11,  2.69it/s]\u001b[A\n"," 44%|████▎     | 148/340 [00:54<01:11,  2.69it/s]\u001b[A\n"," 44%|████▍     | 149/340 [00:54<01:11,  2.69it/s]\u001b[A\n"," 44%|████▍     | 150/340 [00:55<01:10,  2.68it/s]\u001b[A\n"," 44%|████▍     | 151/340 [00:55<01:10,  2.69it/s]\u001b[A\n"," 45%|████▍     | 152/340 [00:55<01:09,  2.71it/s]\u001b[A\n"," 45%|████▌     | 153/340 [00:56<01:09,  2.70it/s]\u001b[A\n"," 45%|████▌     | 154/340 [00:56<01:09,  2.69it/s]\u001b[A\n"," 46%|████▌     | 155/340 [00:56<01:08,  2.69it/s]\u001b[A\n"," 46%|████▌     | 156/340 [00:57<01:08,  2.70it/s]\u001b[A\n"," 46%|████▌     | 157/340 [00:57<01:07,  2.71it/s]\u001b[A\n"," 46%|████▋     | 158/340 [00:58<01:06,  2.72it/s]\u001b[A\n"," 47%|████▋     | 159/340 [00:58<01:06,  2.71it/s]\u001b[A\n"," 47%|████▋     | 160/340 [00:58<01:06,  2.71it/s]\u001b[A\n"," 47%|████▋     | 161/340 [00:59<01:05,  2.71it/s]\u001b[A\n"," 48%|████▊     | 162/340 [00:59<01:05,  2.71it/s]\u001b[A\n"," 48%|████▊     | 163/340 [00:59<01:05,  2.70it/s]\u001b[A\n"," 48%|████▊     | 164/340 [01:00<01:05,  2.69it/s]\u001b[A\n"," 49%|████▊     | 165/340 [01:00<01:05,  2.68it/s]\u001b[A\n"," 49%|████▉     | 166/340 [01:01<01:05,  2.68it/s]\u001b[A\n"," 49%|████▉     | 167/340 [01:01<01:04,  2.68it/s]\u001b[A\n"," 49%|████▉     | 168/340 [01:01<01:04,  2.67it/s]\u001b[A\n"," 50%|████▉     | 169/340 [01:02<01:03,  2.67it/s]\u001b[A\n"," 50%|█████     | 170/340 [01:02<01:03,  2.68it/s]\u001b[A\n"," 50%|█████     | 171/340 [01:02<01:02,  2.69it/s]\u001b[A\n"," 51%|█████     | 172/340 [01:03<01:02,  2.70it/s]\u001b[A\n"," 51%|█████     | 173/340 [01:03<01:01,  2.72it/s]\u001b[A\n"," 51%|█████     | 174/340 [01:04<01:01,  2.71it/s]\u001b[A\n"," 51%|█████▏    | 175/340 [01:04<01:01,  2.70it/s]\u001b[A\n"," 52%|█████▏    | 176/340 [01:04<01:00,  2.71it/s]\u001b[A\n"," 52%|█████▏    | 177/340 [01:05<00:59,  2.72it/s]\u001b[A\n"," 52%|█████▏    | 178/340 [01:05<00:59,  2.72it/s]\u001b[A\n"," 53%|█████▎    | 179/340 [01:05<00:59,  2.70it/s]\u001b[A\n"," 53%|█████▎    | 180/340 [01:06<00:59,  2.71it/s]\u001b[A\n"," 53%|█████▎    | 181/340 [01:06<00:58,  2.70it/s]\u001b[A\n"," 54%|█████▎    | 182/340 [01:06<00:58,  2.69it/s]\u001b[A\n"," 54%|█████▍    | 183/340 [01:07<00:58,  2.68it/s]\u001b[A\n"," 54%|█████▍    | 184/340 [01:07<00:58,  2.67it/s]\u001b[A\n"," 54%|█████▍    | 185/340 [01:08<00:57,  2.69it/s]\u001b[A\n"," 55%|█████▍    | 186/340 [01:08<00:56,  2.70it/s]\u001b[A\n"," 55%|█████▌    | 187/340 [01:08<00:56,  2.69it/s]\u001b[A\n"," 55%|█████▌    | 188/340 [01:09<00:56,  2.69it/s]\u001b[A\n"," 56%|█████▌    | 189/340 [01:09<00:56,  2.68it/s]\u001b[A\n"," 56%|█████▌    | 190/340 [01:09<00:55,  2.68it/s]\u001b[A\n"," 56%|█████▌    | 191/340 [01:10<00:55,  2.69it/s]\u001b[A\n"," 56%|█████▋    | 192/340 [01:10<00:55,  2.68it/s]\u001b[A\n"," 57%|█████▋    | 193/340 [01:11<00:54,  2.68it/s]\u001b[A\n"," 57%|█████▋    | 194/340 [01:11<00:54,  2.67it/s]\u001b[A\n"," 57%|█████▋    | 195/340 [01:11<00:54,  2.67it/s]\u001b[A\n"," 58%|█████▊    | 196/340 [01:12<00:54,  2.67it/s]\u001b[A\n"," 58%|█████▊    | 197/340 [01:12<00:53,  2.66it/s]\u001b[A\n"," 58%|█████▊    | 198/340 [01:12<00:53,  2.66it/s]\u001b[A\n"," 59%|█████▊    | 199/340 [01:13<00:53,  2.66it/s]\u001b[A\n"," 59%|█████▉    | 200/340 [01:13<00:52,  2.66it/s]\u001b[A\n"," 59%|█████▉    | 201/340 [01:14<00:52,  2.66it/s]\u001b[A\n"," 59%|█████▉    | 202/340 [01:14<00:51,  2.66it/s]\u001b[A\n"," 60%|█████▉    | 203/340 [01:14<00:51,  2.66it/s]\u001b[A\n"," 60%|██████    | 204/340 [01:15<00:50,  2.68it/s]\u001b[A\n"," 60%|██████    | 205/340 [01:15<00:50,  2.68it/s]\u001b[A\n"," 61%|██████    | 206/340 [01:15<00:49,  2.68it/s]\u001b[A\n"," 61%|██████    | 207/340 [01:16<00:49,  2.68it/s]\u001b[A\n"," 61%|██████    | 208/340 [01:16<00:49,  2.67it/s]\u001b[A\n"," 61%|██████▏   | 209/340 [01:17<00:49,  2.67it/s]\u001b[A\n"," 62%|██████▏   | 210/340 [01:17<00:48,  2.66it/s]\u001b[A\n"," 62%|██████▏   | 211/340 [01:17<00:48,  2.66it/s]\u001b[A\n"," 62%|██████▏   | 212/340 [01:18<00:48,  2.65it/s]\u001b[A\n"," 63%|██████▎   | 213/340 [01:18<00:47,  2.66it/s]\u001b[A\n"," 63%|██████▎   | 214/340 [01:18<00:47,  2.67it/s]\u001b[A\n"," 63%|██████▎   | 215/340 [01:19<00:46,  2.68it/s]\u001b[A\n"," 64%|██████▎   | 216/340 [01:19<00:46,  2.67it/s]\u001b[A\n"," 64%|██████▍   | 217/340 [01:20<00:46,  2.66it/s]\u001b[A\n"," 64%|██████▍   | 218/340 [01:20<00:45,  2.65it/s]\u001b[A\n"," 64%|██████▍   | 219/340 [01:20<00:45,  2.65it/s]\u001b[A\n"," 65%|██████▍   | 220/340 [01:21<00:45,  2.66it/s]\u001b[A\n"," 65%|██████▌   | 221/340 [01:21<00:44,  2.66it/s]\u001b[A\n"," 65%|██████▌   | 222/340 [01:21<00:44,  2.68it/s]\u001b[A\n"," 66%|██████▌   | 223/340 [01:22<00:43,  2.67it/s]\u001b[A\n"," 66%|██████▌   | 224/340 [01:22<00:43,  2.66it/s]\u001b[A\n"," 66%|██████▌   | 225/340 [01:23<00:43,  2.65it/s]\u001b[A\n"," 66%|██████▋   | 226/340 [01:23<00:42,  2.65it/s]\u001b[A\n"," 67%|██████▋   | 227/340 [01:23<00:42,  2.67it/s]\u001b[A\n"," 67%|██████▋   | 228/340 [01:24<00:41,  2.67it/s]\u001b[A\n"," 67%|██████▋   | 229/340 [01:24<00:41,  2.67it/s]\u001b[A\n"," 68%|██████▊   | 230/340 [01:24<00:41,  2.67it/s]\u001b[A\n"," 68%|██████▊   | 231/340 [01:25<00:40,  2.66it/s]\u001b[A\n"," 68%|██████▊   | 232/340 [01:25<00:40,  2.66it/s]\u001b[A\n"," 69%|██████▊   | 233/340 [01:26<00:40,  2.65it/s]\u001b[A\n"," 69%|██████▉   | 234/340 [01:26<00:40,  2.64it/s]\u001b[A\n"," 69%|██████▉   | 235/340 [01:26<00:39,  2.65it/s]\u001b[A\n"," 69%|██████▉   | 236/340 [01:27<00:39,  2.65it/s]\u001b[A\n"," 70%|██████▉   | 237/340 [01:27<00:38,  2.64it/s]\u001b[A\n"," 70%|███████   | 238/340 [01:28<00:38,  2.64it/s]\u001b[A\n"," 70%|███████   | 239/340 [01:28<00:38,  2.63it/s]\u001b[A\n"," 71%|███████   | 240/340 [01:28<00:37,  2.65it/s]\u001b[A\n"," 71%|███████   | 241/340 [01:29<00:37,  2.65it/s]\u001b[A\n"," 71%|███████   | 242/340 [01:29<00:36,  2.67it/s]\u001b[A\n"," 71%|███████▏  | 243/340 [01:29<00:36,  2.66it/s]\u001b[A\n"," 72%|███████▏  | 244/340 [01:30<00:36,  2.64it/s]\u001b[A\n"," 72%|███████▏  | 245/340 [01:30<00:35,  2.65it/s]\u001b[A\n"," 72%|███████▏  | 246/340 [01:31<00:35,  2.65it/s]\u001b[A\n"," 73%|███████▎  | 247/340 [01:31<00:35,  2.64it/s]\u001b[A\n"," 73%|███████▎  | 248/340 [01:31<00:34,  2.65it/s]\u001b[A\n"," 73%|███████▎  | 249/340 [01:32<00:34,  2.65it/s]\u001b[A\n"," 74%|███████▎  | 250/340 [01:32<00:34,  2.64it/s]\u001b[A\n"," 74%|███████▍  | 251/340 [01:32<00:33,  2.64it/s]\u001b[A\n"," 74%|███████▍  | 252/340 [01:33<00:33,  2.64it/s]\u001b[A\n"," 74%|███████▍  | 253/340 [01:33<00:33,  2.63it/s]\u001b[A\n"," 75%|███████▍  | 254/340 [01:34<00:32,  2.65it/s]\u001b[A\n"," 75%|███████▌  | 255/340 [01:34<00:32,  2.64it/s]\u001b[A\n"," 75%|███████▌  | 256/340 [01:34<00:31,  2.64it/s]\u001b[A\n"," 76%|███████▌  | 257/340 [01:35<00:31,  2.64it/s]\u001b[A\n"," 76%|███████▌  | 258/340 [01:35<00:31,  2.63it/s]\u001b[A\n"," 76%|███████▌  | 259/340 [01:35<00:30,  2.66it/s]\u001b[A\n"," 76%|███████▋  | 260/340 [01:36<00:30,  2.64it/s]\u001b[A\n"," 77%|███████▋  | 261/340 [01:36<00:29,  2.64it/s]\u001b[A\n"," 77%|███████▋  | 262/340 [01:37<00:29,  2.65it/s]\u001b[A\n"," 77%|███████▋  | 263/340 [01:37<00:29,  2.64it/s]\u001b[A\n"," 78%|███████▊  | 264/340 [01:37<00:28,  2.67it/s]\u001b[A\n"," 78%|███████▊  | 265/340 [01:38<00:28,  2.67it/s]\u001b[A\n"," 78%|███████▊  | 266/340 [01:38<00:27,  2.66it/s]\u001b[A\n"," 79%|███████▊  | 267/340 [01:38<00:27,  2.65it/s]\u001b[A\n"," 79%|███████▉  | 268/340 [01:39<00:26,  2.67it/s]\u001b[A\n"," 79%|███████▉  | 269/340 [01:39<00:26,  2.66it/s]\u001b[A\n"," 79%|███████▉  | 270/340 [01:40<00:26,  2.66it/s]\u001b[A\n"," 80%|███████▉  | 271/340 [01:40<00:26,  2.65it/s]\u001b[A\n"," 80%|████████  | 272/340 [01:40<00:25,  2.64it/s]\u001b[A\n"," 80%|████████  | 273/340 [01:41<00:25,  2.64it/s]\u001b[A\n"," 81%|████████  | 274/340 [01:41<00:25,  2.64it/s]\u001b[A\n"," 81%|████████  | 275/340 [01:41<00:24,  2.64it/s]\u001b[A\n"," 81%|████████  | 276/340 [01:42<00:24,  2.63it/s]\u001b[A\n"," 81%|████████▏ | 277/340 [01:42<00:24,  2.62it/s]\u001b[A\n"," 82%|████████▏ | 278/340 [01:43<00:23,  2.62it/s]\u001b[A\n"," 82%|████████▏ | 279/340 [01:43<00:23,  2.61it/s]\u001b[A\n"," 82%|████████▏ | 280/340 [01:43<00:23,  2.60it/s]\u001b[A\n"," 83%|████████▎ | 281/340 [01:44<00:22,  2.61it/s]\u001b[A\n"," 83%|████████▎ | 282/340 [01:44<00:22,  2.60it/s]\u001b[A\n"," 83%|████████▎ | 283/340 [01:45<00:21,  2.60it/s]\u001b[A\n"," 84%|████████▎ | 284/340 [01:45<00:21,  2.60it/s]\u001b[A\n"," 84%|████████▍ | 285/340 [01:45<00:21,  2.61it/s]\u001b[A\n"," 84%|████████▍ | 286/340 [01:46<00:20,  2.64it/s]\u001b[A\n"," 84%|████████▍ | 287/340 [01:46<00:20,  2.64it/s]\u001b[A\n"," 85%|████████▍ | 288/340 [01:46<00:19,  2.64it/s]\u001b[A\n"," 85%|████████▌ | 289/340 [01:47<00:19,  2.64it/s]\u001b[A\n"," 85%|████████▌ | 290/340 [01:47<00:18,  2.65it/s]\u001b[A\n"," 86%|████████▌ | 291/340 [01:48<00:18,  2.63it/s]\u001b[A\n"," 86%|████████▌ | 292/340 [01:48<00:18,  2.63it/s]\u001b[A\n"," 86%|████████▌ | 293/340 [01:48<00:17,  2.63it/s]\u001b[A\n"," 86%|████████▋ | 294/340 [01:49<00:17,  2.63it/s]\u001b[A\n"," 87%|████████▋ | 295/340 [01:49<00:17,  2.62it/s]\u001b[A\n"," 87%|████████▋ | 296/340 [01:49<00:16,  2.63it/s]\u001b[A\n"," 87%|████████▋ | 297/340 [01:50<00:16,  2.64it/s]\u001b[A\n"," 88%|████████▊ | 298/340 [01:50<00:15,  2.63it/s]\u001b[A\n"," 88%|████████▊ | 299/340 [01:51<00:15,  2.63it/s]\u001b[A\n"," 88%|████████▊ | 300/340 [01:51<00:15,  2.64it/s]\u001b[A\n"," 89%|████████▊ | 301/340 [01:51<00:14,  2.65it/s]\u001b[A\n"," 89%|████████▉ | 302/340 [01:52<00:14,  2.63it/s]\u001b[A\n"," 89%|████████▉ | 303/340 [01:52<00:14,  2.64it/s]\u001b[A\n"," 89%|████████▉ | 304/340 [01:53<00:13,  2.64it/s]\u001b[A\n"," 90%|████████▉ | 305/340 [01:53<00:13,  2.63it/s]\u001b[A\n"," 90%|█████████ | 306/340 [01:53<00:12,  2.67it/s]\u001b[A\n"," 90%|█████████ | 307/340 [01:54<00:12,  2.67it/s]\u001b[A\n"," 91%|█████████ | 308/340 [01:54<00:12,  2.65it/s]\u001b[A\n"," 91%|█████████ | 309/340 [01:54<00:11,  2.64it/s]\u001b[A\n"," 91%|█████████ | 310/340 [01:55<00:11,  2.63it/s]\u001b[A\n"," 91%|█████████▏| 311/340 [01:55<00:11,  2.63it/s]\u001b[A\n"," 92%|█████████▏| 312/340 [01:56<00:10,  2.64it/s]\u001b[A\n"," 92%|█████████▏| 313/340 [01:56<00:10,  2.67it/s]\u001b[A\n"," 92%|█████████▏| 314/340 [01:56<00:09,  2.65it/s]\u001b[A\n"," 93%|█████████▎| 315/340 [01:57<00:09,  2.65it/s]\u001b[A\n"," 93%|█████████▎| 316/340 [01:57<00:09,  2.64it/s]\u001b[A\n"," 93%|█████████▎| 317/340 [01:57<00:08,  2.64it/s]\u001b[A\n"," 94%|█████████▎| 318/340 [01:58<00:08,  2.64it/s]\u001b[A\n"," 94%|█████████▍| 319/340 [01:58<00:08,  2.62it/s]\u001b[A\n"," 94%|█████████▍| 320/340 [01:59<00:07,  2.63it/s]\u001b[A\n"," 94%|█████████▍| 321/340 [01:59<00:07,  2.63it/s]\u001b[A\n"," 95%|█████████▍| 322/340 [01:59<00:06,  2.61it/s]\u001b[A\n"," 95%|█████████▌| 323/340 [02:00<00:06,  2.61it/s]\u001b[A\n"," 95%|█████████▌| 324/340 [02:00<00:06,  2.62it/s]\u001b[A\n"," 96%|█████████▌| 325/340 [02:01<00:05,  2.61it/s]\u001b[A\n"," 96%|█████████▌| 326/340 [02:01<00:05,  2.61it/s]\u001b[A\n"," 96%|█████████▌| 327/340 [02:01<00:04,  2.62it/s]\u001b[A\n"," 96%|█████████▋| 328/340 [02:02<00:04,  2.64it/s]\u001b[A\n"," 97%|█████████▋| 329/340 [02:02<00:04,  2.63it/s]\u001b[A\n"," 97%|█████████▋| 330/340 [02:02<00:03,  2.62it/s]\u001b[A\n"," 97%|█████████▋| 331/340 [02:03<00:03,  2.62it/s]\u001b[A\n"," 98%|█████████▊| 332/340 [02:03<00:03,  2.63it/s]\u001b[A\n"," 98%|█████████▊| 333/340 [02:04<00:02,  2.63it/s]\u001b[A\n"," 98%|█████████▊| 334/340 [02:04<00:02,  2.62it/s]\u001b[A\n"," 99%|█████████▊| 335/340 [02:04<00:01,  2.61it/s]\u001b[A\n"," 99%|█████████▉| 336/340 [02:05<00:01,  2.60it/s]\u001b[A\n"," 99%|█████████▉| 337/340 [02:05<00:01,  2.61it/s]\u001b[A\n"," 99%|█████████▉| 338/340 [02:05<00:00,  2.63it/s]\u001b[A\n","100%|█████████▉| 339/340 [02:06<00:00,  2.62it/s]\u001b[A\n","100%|██████████| 340/340 [02:06<00:00,  2.68it/s]\n"]},{"output_type":"stream","name":"stdout","text":["Epochs: 1 | Train Loss:  0.229             | Train Accuracy:  0.560             | Val Loss:  0.186             | Val Accuracy:  0.688\n"]},{"output_type":"stream","name":"stderr","text":["\n","  0%|          | 0/340 [00:00<?, ?it/s]\u001b[A\n","  0%|          | 1/340 [00:00<02:03,  2.74it/s]\u001b[A\n","  1%|          | 2/340 [00:00<02:06,  2.68it/s]\u001b[A\n","  1%|          | 3/340 [00:01<02:08,  2.63it/s]\u001b[A\n","  1%|          | 4/340 [00:01<02:07,  2.64it/s]\u001b[A\n","  1%|▏         | 5/340 [00:01<02:06,  2.64it/s]\u001b[A\n","  2%|▏         | 6/340 [00:02<02:07,  2.63it/s]\u001b[A\n","  2%|▏         | 7/340 [00:02<02:07,  2.62it/s]\u001b[A\n","  2%|▏         | 8/340 [00:03<02:07,  2.61it/s]\u001b[A\n","  3%|▎         | 9/340 [00:03<02:07,  2.61it/s]\u001b[A\n","  3%|▎         | 10/340 [00:03<02:05,  2.62it/s]\u001b[A\n","  3%|▎         | 11/340 [00:04<02:04,  2.63it/s]\u001b[A\n","  4%|▎         | 12/340 [00:04<02:04,  2.63it/s]\u001b[A\n","  4%|▍         | 13/340 [00:04<02:04,  2.62it/s]\u001b[A\n","  4%|▍         | 14/340 [00:05<02:04,  2.62it/s]\u001b[A\n","  4%|▍         | 15/340 [00:05<02:04,  2.60it/s]\u001b[A\n","  5%|▍         | 16/340 [00:06<02:04,  2.61it/s]\u001b[A\n","  5%|▌         | 17/340 [00:06<02:04,  2.60it/s]\u001b[A\n","  5%|▌         | 18/340 [00:06<02:03,  2.60it/s]\u001b[A\n","  6%|▌         | 19/340 [00:07<02:02,  2.62it/s]\u001b[A\n","  6%|▌         | 20/340 [00:07<02:02,  2.60it/s]\u001b[A\n","  6%|▌         | 21/340 [00:08<02:01,  2.63it/s]\u001b[A\n","  6%|▋         | 22/340 [00:08<02:01,  2.63it/s]\u001b[A\n","  7%|▋         | 23/340 [00:08<02:00,  2.64it/s]\u001b[A\n","  7%|▋         | 24/340 [00:09<02:00,  2.62it/s]\u001b[A\n","  7%|▋         | 25/340 [00:09<02:00,  2.61it/s]\u001b[A\n","  8%|▊         | 26/340 [00:09<01:59,  2.63it/s]\u001b[A\n","  8%|▊         | 27/340 [00:10<01:57,  2.65it/s]\u001b[A\n","  8%|▊         | 28/340 [00:10<01:58,  2.63it/s]\u001b[A\n","  9%|▊         | 29/340 [00:11<01:58,  2.62it/s]\u001b[A\n","  9%|▉         | 30/340 [00:11<01:58,  2.61it/s]\u001b[A\n","  9%|▉         | 31/340 [00:11<01:58,  2.60it/s]\u001b[A\n","  9%|▉         | 32/340 [00:12<01:58,  2.61it/s]\u001b[A\n"," 10%|▉         | 33/340 [00:12<01:57,  2.62it/s]\u001b[A\n"," 10%|█         | 34/340 [00:12<01:56,  2.63it/s]\u001b[A\n"," 10%|█         | 35/340 [00:13<01:56,  2.62it/s]\u001b[A\n"," 11%|█         | 36/340 [00:13<01:55,  2.63it/s]\u001b[A\n"," 11%|█         | 37/340 [00:14<01:54,  2.64it/s]\u001b[A\n"," 11%|█         | 38/340 [00:14<01:54,  2.64it/s]\u001b[A\n"," 11%|█▏        | 39/340 [00:14<01:54,  2.63it/s]\u001b[A\n"," 12%|█▏        | 40/340 [00:15<01:54,  2.62it/s]\u001b[A\n"," 12%|█▏        | 41/340 [00:15<01:54,  2.62it/s]\u001b[A\n"," 12%|█▏        | 42/340 [00:16<01:54,  2.60it/s]\u001b[A\n"," 13%|█▎        | 43/340 [00:16<01:53,  2.61it/s]\u001b[A\n"," 13%|█▎        | 44/340 [00:16<01:53,  2.60it/s]\u001b[A\n"," 13%|█▎        | 45/340 [00:17<01:53,  2.59it/s]\u001b[A\n"," 14%|█▎        | 46/340 [00:17<01:53,  2.60it/s]\u001b[A\n"," 14%|█▍        | 47/340 [00:17<01:53,  2.59it/s]\u001b[A\n"," 14%|█▍        | 48/340 [00:18<01:52,  2.59it/s]\u001b[A\n"," 14%|█▍        | 49/340 [00:18<01:52,  2.59it/s]\u001b[A\n"," 15%|█▍        | 50/340 [00:19<01:52,  2.59it/s]\u001b[A\n"," 15%|█▌        | 51/340 [00:19<01:52,  2.58it/s]\u001b[A\n"," 15%|█▌        | 52/340 [00:19<01:51,  2.58it/s]\u001b[A\n"," 16%|█▌        | 53/340 [00:20<01:51,  2.58it/s]\u001b[A\n"," 16%|█▌        | 54/340 [00:20<01:50,  2.59it/s]\u001b[A\n"," 16%|█▌        | 55/340 [00:21<01:49,  2.59it/s]\u001b[A\n"," 16%|█▋        | 56/340 [00:21<01:49,  2.60it/s]\u001b[A\n"," 17%|█▋        | 57/340 [00:21<01:48,  2.60it/s]\u001b[A\n"," 17%|█▋        | 58/340 [00:22<01:48,  2.59it/s]\u001b[A\n"," 17%|█▋        | 59/340 [00:22<01:48,  2.58it/s]\u001b[A\n"," 18%|█▊        | 60/340 [00:22<01:47,  2.61it/s]\u001b[A\n"," 18%|█▊        | 61/340 [00:23<01:47,  2.60it/s]\u001b[A\n"," 18%|█▊        | 62/340 [00:23<01:46,  2.60it/s]\u001b[A\n"," 19%|█▊        | 63/340 [00:24<01:46,  2.59it/s]\u001b[A\n"," 19%|█▉        | 64/340 [00:24<01:46,  2.59it/s]\u001b[A\n"," 19%|█▉        | 65/340 [00:24<01:46,  2.58it/s]\u001b[A\n"," 19%|█▉        | 66/340 [00:25<01:46,  2.57it/s]\u001b[A\n"," 20%|█▉        | 67/340 [00:25<01:45,  2.59it/s]\u001b[A\n"," 20%|██        | 68/340 [00:26<01:44,  2.59it/s]\u001b[A\n"," 20%|██        | 69/340 [00:26<01:44,  2.60it/s]\u001b[A\n"," 21%|██        | 70/340 [00:26<01:43,  2.60it/s]\u001b[A\n"," 21%|██        | 71/340 [00:27<01:44,  2.59it/s]\u001b[A\n"," 21%|██        | 72/340 [00:27<01:43,  2.58it/s]\u001b[A\n"," 21%|██▏       | 73/340 [00:27<01:42,  2.59it/s]\u001b[A\n"," 22%|██▏       | 74/340 [00:28<01:42,  2.60it/s]\u001b[A\n"," 22%|██▏       | 75/340 [00:28<01:42,  2.60it/s]\u001b[A\n"," 22%|██▏       | 76/340 [00:29<01:42,  2.59it/s]\u001b[A\n"," 23%|██▎       | 77/340 [00:29<01:40,  2.60it/s]\u001b[A\n"," 23%|██▎       | 78/340 [00:29<01:40,  2.61it/s]\u001b[A\n"," 23%|██▎       | 79/340 [00:30<01:40,  2.59it/s]\u001b[A\n"," 24%|██▎       | 80/340 [00:30<01:40,  2.60it/s]\u001b[A\n"," 24%|██▍       | 81/340 [00:31<01:39,  2.59it/s]\u001b[A\n"," 24%|██▍       | 82/340 [00:31<01:39,  2.60it/s]\u001b[A\n"," 24%|██▍       | 83/340 [00:31<01:39,  2.59it/s]\u001b[A\n"," 25%|██▍       | 84/340 [00:32<01:39,  2.58it/s]\u001b[A\n"," 25%|██▌       | 85/340 [00:32<01:38,  2.59it/s]\u001b[A\n"," 25%|██▌       | 86/340 [00:33<01:38,  2.58it/s]\u001b[A\n"," 26%|██▌       | 87/340 [00:33<01:37,  2.59it/s]\u001b[A\n"," 26%|██▌       | 88/340 [00:33<01:36,  2.60it/s]\u001b[A\n"," 26%|██▌       | 89/340 [00:34<01:36,  2.59it/s]\u001b[A\n"," 26%|██▋       | 90/340 [00:34<01:36,  2.58it/s]\u001b[A\n"," 27%|██▋       | 91/340 [00:34<01:36,  2.59it/s]\u001b[A\n"," 27%|██▋       | 92/340 [00:35<01:36,  2.58it/s]\u001b[A\n"," 27%|██▋       | 93/340 [00:35<01:34,  2.60it/s]\u001b[A\n"," 28%|██▊       | 94/340 [00:36<01:34,  2.60it/s]\u001b[A\n"," 28%|██▊       | 95/340 [00:36<01:34,  2.60it/s]\u001b[A\n"," 28%|██▊       | 96/340 [00:36<01:34,  2.59it/s]\u001b[A\n"," 29%|██▊       | 97/340 [00:37<01:34,  2.58it/s]\u001b[A\n"," 29%|██▉       | 98/340 [00:37<01:34,  2.57it/s]\u001b[A\n"," 29%|██▉       | 99/340 [00:38<01:33,  2.57it/s]\u001b[A\n"," 29%|██▉       | 100/340 [00:38<01:33,  2.57it/s]\u001b[A\n"," 30%|██▉       | 101/340 [00:38<01:32,  2.58it/s]\u001b[A\n"," 30%|███       | 102/340 [00:39<01:32,  2.58it/s]\u001b[A\n"," 30%|███       | 103/340 [00:39<01:32,  2.57it/s]\u001b[A\n"," 31%|███       | 104/340 [00:39<01:31,  2.57it/s]\u001b[A\n"," 31%|███       | 105/340 [00:40<01:31,  2.57it/s]\u001b[A\n"," 31%|███       | 106/340 [00:40<01:31,  2.56it/s]\u001b[A\n"," 31%|███▏      | 107/340 [00:41<01:31,  2.56it/s]\u001b[A\n"," 32%|███▏      | 108/340 [00:41<01:30,  2.55it/s]\u001b[A\n"," 32%|███▏      | 109/340 [00:41<01:30,  2.55it/s]\u001b[A\n"," 32%|███▏      | 110/340 [00:42<01:30,  2.55it/s]\u001b[A\n"," 33%|███▎      | 111/340 [00:42<01:29,  2.57it/s]\u001b[A\n"," 33%|███▎      | 112/340 [00:43<01:28,  2.58it/s]\u001b[A\n"," 33%|███▎      | 113/340 [00:43<01:28,  2.58it/s]\u001b[A\n"," 34%|███▎      | 114/340 [00:43<01:27,  2.58it/s]\u001b[A\n"," 34%|███▍      | 115/340 [00:44<01:27,  2.58it/s]\u001b[A\n"," 34%|███▍      | 116/340 [00:44<01:27,  2.57it/s]\u001b[A\n"," 34%|███▍      | 117/340 [00:45<01:26,  2.57it/s]\u001b[A\n"," 35%|███▍      | 118/340 [00:45<01:26,  2.57it/s]\u001b[A\n"," 35%|███▌      | 119/340 [00:45<01:26,  2.56it/s]\u001b[A\n"," 35%|███▌      | 120/340 [00:46<01:25,  2.57it/s]\u001b[A\n"," 36%|███▌      | 121/340 [00:46<01:25,  2.58it/s]\u001b[A\n"," 36%|███▌      | 122/340 [00:46<01:24,  2.57it/s]\u001b[A\n"," 36%|███▌      | 123/340 [00:47<01:24,  2.56it/s]\u001b[A\n"," 36%|███▋      | 124/340 [00:47<01:24,  2.57it/s]\u001b[A\n"," 37%|███▋      | 125/340 [00:48<01:23,  2.58it/s]\u001b[A\n"," 37%|███▋      | 126/340 [00:48<01:22,  2.60it/s]\u001b[A\n"," 37%|███▋      | 127/340 [00:48<01:22,  2.59it/s]\u001b[A\n"," 38%|███▊      | 128/340 [00:49<01:21,  2.59it/s]\u001b[A\n"," 38%|███▊      | 129/340 [00:49<01:21,  2.59it/s]\u001b[A\n"," 38%|███▊      | 130/340 [00:50<01:21,  2.58it/s]\u001b[A\n"," 39%|███▊      | 131/340 [00:50<01:21,  2.57it/s]\u001b[A\n"," 39%|███▉      | 132/340 [00:50<01:20,  2.59it/s]\u001b[A\n"," 39%|███▉      | 133/340 [00:51<01:19,  2.59it/s]\u001b[A\n"," 39%|███▉      | 134/340 [00:51<01:19,  2.58it/s]\u001b[A\n"," 40%|███▉      | 135/340 [00:52<01:19,  2.57it/s]\u001b[A\n"," 40%|████      | 136/340 [00:52<01:19,  2.56it/s]\u001b[A\n"," 40%|████      | 137/340 [00:52<01:19,  2.57it/s]\u001b[A\n"," 41%|████      | 138/340 [00:53<01:18,  2.57it/s]\u001b[A\n"," 41%|████      | 139/340 [00:53<01:18,  2.56it/s]\u001b[A\n"," 41%|████      | 140/340 [00:53<01:18,  2.56it/s]\u001b[A\n"," 41%|████▏     | 141/340 [00:54<01:17,  2.56it/s]\u001b[A\n"," 42%|████▏     | 142/340 [00:54<01:17,  2.55it/s]\u001b[A\n"," 42%|████▏     | 143/340 [00:55<01:16,  2.59it/s]\u001b[A\n"," 42%|████▏     | 144/340 [00:55<01:15,  2.58it/s]\u001b[A\n"," 43%|████▎     | 145/340 [00:55<01:15,  2.57it/s]\u001b[A\n"," 43%|████▎     | 146/340 [00:56<01:15,  2.58it/s]\u001b[A\n"," 43%|████▎     | 147/340 [00:56<01:14,  2.59it/s]\u001b[A\n"," 44%|████▎     | 148/340 [00:57<01:13,  2.60it/s]\u001b[A\n"," 44%|████▍     | 149/340 [00:57<01:13,  2.60it/s]\u001b[A\n"," 44%|████▍     | 150/340 [00:57<01:13,  2.58it/s]\u001b[A\n"," 44%|████▍     | 151/340 [00:58<01:13,  2.57it/s]\u001b[A\n"," 45%|████▍     | 152/340 [00:58<01:13,  2.57it/s]\u001b[A\n"," 45%|████▌     | 153/340 [00:59<01:12,  2.57it/s]\u001b[A\n"," 45%|████▌     | 154/340 [00:59<01:12,  2.56it/s]\u001b[A\n"," 46%|████▌     | 155/340 [00:59<01:12,  2.56it/s]\u001b[A\n"," 46%|████▌     | 156/340 [01:00<01:11,  2.57it/s]\u001b[A\n"," 46%|████▌     | 157/340 [01:00<01:10,  2.59it/s]\u001b[A\n"," 46%|████▋     | 158/340 [01:00<01:10,  2.60it/s]\u001b[A\n"," 47%|████▋     | 159/340 [01:01<01:10,  2.58it/s]\u001b[A\n"," 47%|████▋     | 160/340 [01:01<01:10,  2.57it/s]\u001b[A\n"," 47%|████▋     | 161/340 [01:02<01:09,  2.57it/s]\u001b[A\n"," 48%|████▊     | 162/340 [01:02<01:09,  2.56it/s]\u001b[A\n"," 48%|████▊     | 163/340 [01:02<01:09,  2.55it/s]\u001b[A\n"," 48%|████▊     | 164/340 [01:03<01:08,  2.56it/s]\u001b[A\n"," 49%|████▊     | 165/340 [01:03<01:08,  2.55it/s]\u001b[A\n"," 49%|████▉     | 166/340 [01:04<01:08,  2.56it/s]\u001b[A\n"," 49%|████▉     | 167/340 [01:04<01:07,  2.55it/s]\u001b[A\n"," 49%|████▉     | 168/340 [01:04<01:07,  2.56it/s]\u001b[A\n"," 50%|████▉     | 169/340 [01:05<01:06,  2.57it/s]\u001b[A\n"," 50%|█████     | 170/340 [01:05<01:05,  2.59it/s]\u001b[A\n"," 50%|█████     | 171/340 [01:06<01:05,  2.57it/s]\u001b[A\n"," 51%|█████     | 172/340 [01:06<01:05,  2.56it/s]\u001b[A\n"," 51%|█████     | 173/340 [01:06<01:05,  2.56it/s]\u001b[A\n"," 51%|█████     | 174/340 [01:07<01:04,  2.57it/s]\u001b[A\n"," 51%|█████▏    | 175/340 [01:07<01:04,  2.57it/s]\u001b[A\n"," 52%|█████▏    | 176/340 [01:07<01:04,  2.56it/s]\u001b[A\n"," 52%|█████▏    | 177/340 [01:08<01:03,  2.57it/s]\u001b[A\n"," 52%|█████▏    | 178/340 [01:08<01:03,  2.57it/s]\u001b[A\n"," 53%|█████▎    | 179/340 [01:09<01:02,  2.56it/s]\u001b[A\n"," 53%|█████▎    | 180/340 [01:09<01:02,  2.57it/s]\u001b[A\n"," 53%|█████▎    | 181/340 [01:09<01:01,  2.57it/s]\u001b[A\n"," 54%|█████▎    | 182/340 [01:10<01:01,  2.56it/s]\u001b[A\n"," 54%|█████▍    | 183/340 [01:10<01:01,  2.56it/s]\u001b[A\n"," 54%|█████▍    | 184/340 [01:11<01:00,  2.58it/s]\u001b[A\n"," 54%|█████▍    | 185/340 [01:11<01:00,  2.57it/s]\u001b[A\n"," 55%|█████▍    | 186/340 [01:11<01:00,  2.56it/s]\u001b[A\n"," 55%|█████▌    | 187/340 [01:12<00:59,  2.56it/s]\u001b[A\n"," 55%|█████▌    | 188/340 [01:12<00:58,  2.58it/s]\u001b[A\n"," 56%|█████▌    | 189/340 [01:13<00:58,  2.57it/s]\u001b[A\n"," 56%|█████▌    | 190/340 [01:13<00:58,  2.57it/s]\u001b[A\n"," 56%|█████▌    | 191/340 [01:13<00:58,  2.56it/s]\u001b[A\n"," 56%|█████▋    | 192/340 [01:14<00:57,  2.56it/s]\u001b[A\n"," 57%|█████▋    | 193/340 [01:14<00:57,  2.55it/s]\u001b[A\n"," 57%|█████▋    | 194/340 [01:15<00:57,  2.55it/s]\u001b[A\n"," 57%|█████▋    | 195/340 [01:15<00:56,  2.55it/s]\u001b[A\n"," 58%|█████▊    | 196/340 [01:15<00:56,  2.55it/s]\u001b[A\n"," 58%|█████▊    | 197/340 [01:16<00:56,  2.55it/s]\u001b[A\n"," 58%|█████▊    | 198/340 [01:16<00:55,  2.55it/s]\u001b[A\n"," 59%|█████▊    | 199/340 [01:16<00:55,  2.55it/s]\u001b[A\n"," 59%|█████▉    | 200/340 [01:17<00:55,  2.54it/s]\u001b[A\n"," 59%|█████▉    | 201/340 [01:17<00:54,  2.55it/s]\u001b[A\n"," 59%|█████▉    | 202/340 [01:18<00:54,  2.54it/s]\u001b[A\n"," 60%|█████▉    | 203/340 [01:18<00:53,  2.54it/s]\u001b[A\n"," 60%|██████    | 204/340 [01:18<00:53,  2.54it/s]\u001b[A\n"," 60%|██████    | 205/340 [01:19<00:53,  2.53it/s]\u001b[A\n"," 61%|██████    | 206/340 [01:19<00:52,  2.55it/s]\u001b[A\n"," 61%|██████    | 207/340 [01:20<00:52,  2.55it/s]\u001b[A\n"," 61%|██████    | 208/340 [01:20<00:51,  2.55it/s]\u001b[A\n"," 61%|██████▏   | 209/340 [01:20<00:51,  2.55it/s]\u001b[A\n"," 62%|██████▏   | 210/340 [01:21<00:51,  2.55it/s]\u001b[A\n"," 62%|██████▏   | 211/340 [01:21<00:50,  2.55it/s]\u001b[A\n"," 62%|██████▏   | 212/340 [01:22<00:50,  2.55it/s]\u001b[A\n"," 63%|██████▎   | 213/340 [01:22<00:50,  2.53it/s]\u001b[A\n"," 63%|██████▎   | 214/340 [01:22<00:49,  2.55it/s]\u001b[A\n"," 63%|██████▎   | 215/340 [01:23<00:48,  2.56it/s]\u001b[A\n"," 64%|██████▎   | 216/340 [01:23<00:48,  2.56it/s]\u001b[A\n"," 64%|██████▍   | 217/340 [01:24<00:48,  2.56it/s]\u001b[A\n"," 64%|██████▍   | 218/340 [01:24<00:47,  2.56it/s]\u001b[A\n"," 64%|██████▍   | 219/340 [01:24<00:47,  2.56it/s]\u001b[A\n"," 65%|██████▍   | 220/340 [01:25<00:46,  2.56it/s]\u001b[A\n"," 65%|██████▌   | 221/340 [01:25<00:46,  2.55it/s]\u001b[A\n"," 65%|██████▌   | 222/340 [01:25<00:45,  2.57it/s]\u001b[A\n"," 66%|██████▌   | 223/340 [01:26<00:45,  2.56it/s]\u001b[A\n"," 66%|██████▌   | 224/340 [01:26<00:45,  2.55it/s]\u001b[A\n"," 66%|██████▌   | 225/340 [01:27<00:45,  2.55it/s]\u001b[A\n"," 66%|██████▋   | 226/340 [01:27<00:44,  2.55it/s]\u001b[A\n"," 67%|██████▋   | 227/340 [01:27<00:44,  2.56it/s]\u001b[A\n"," 67%|██████▋   | 228/340 [01:28<00:43,  2.57it/s]\u001b[A\n"," 67%|██████▋   | 229/340 [01:28<00:43,  2.56it/s]\u001b[A\n"," 68%|██████▊   | 230/340 [01:29<00:43,  2.55it/s]\u001b[A\n"," 68%|██████▊   | 231/340 [01:29<00:42,  2.55it/s]\u001b[A\n"," 68%|██████▊   | 232/340 [01:29<00:42,  2.55it/s]\u001b[A\n"," 69%|██████▊   | 233/340 [01:30<00:42,  2.53it/s]\u001b[A\n"," 69%|██████▉   | 234/340 [01:30<00:41,  2.54it/s]\u001b[A\n"," 69%|██████▉   | 235/340 [01:31<00:41,  2.53it/s]\u001b[A\n"," 69%|██████▉   | 236/340 [01:31<00:40,  2.54it/s]\u001b[A\n"," 70%|██████▉   | 237/340 [01:31<00:40,  2.54it/s]\u001b[A\n"," 70%|███████   | 238/340 [01:32<00:40,  2.53it/s]\u001b[A\n"," 70%|███████   | 239/340 [01:32<00:39,  2.54it/s]\u001b[A\n"," 71%|███████   | 240/340 [01:33<00:39,  2.54it/s]\u001b[A\n"," 71%|███████   | 241/340 [01:33<00:38,  2.54it/s]\u001b[A\n"," 71%|███████   | 242/340 [01:33<00:38,  2.54it/s]\u001b[A\n"," 71%|███████▏  | 243/340 [01:34<00:38,  2.55it/s]\u001b[A\n"," 72%|███████▏  | 244/340 [01:34<00:37,  2.55it/s]\u001b[A\n"," 72%|███████▏  | 245/340 [01:35<00:37,  2.55it/s]\u001b[A\n"," 72%|███████▏  | 246/340 [01:35<00:36,  2.55it/s]\u001b[A\n"," 73%|███████▎  | 247/340 [01:35<00:36,  2.54it/s]\u001b[A\n"," 73%|███████▎  | 248/340 [01:36<00:36,  2.54it/s]\u001b[A\n"," 73%|███████▎  | 249/340 [01:36<00:35,  2.56it/s]\u001b[A\n"," 74%|███████▎  | 250/340 [01:36<00:35,  2.55it/s]\u001b[A\n"," 74%|███████▍  | 251/340 [01:37<00:35,  2.54it/s]\u001b[A\n"," 74%|███████▍  | 252/340 [01:37<00:34,  2.55it/s]\u001b[A\n"," 74%|███████▍  | 253/340 [01:38<00:33,  2.56it/s]\u001b[A\n"," 75%|███████▍  | 254/340 [01:38<00:33,  2.56it/s]\u001b[A\n"," 75%|███████▌  | 255/340 [01:38<00:33,  2.56it/s]\u001b[A\n"," 75%|███████▌  | 256/340 [01:39<00:32,  2.55it/s]\u001b[A\n"," 76%|███████▌  | 257/340 [01:39<00:32,  2.54it/s]\u001b[A\n"," 76%|███████▌  | 258/340 [01:40<00:32,  2.54it/s]\u001b[A\n"," 76%|███████▌  | 259/340 [01:40<00:31,  2.54it/s]\u001b[A\n"," 76%|███████▋  | 260/340 [01:40<00:31,  2.54it/s]\u001b[A\n"," 77%|███████▋  | 261/340 [01:41<00:31,  2.54it/s]\u001b[A\n"," 77%|███████▋  | 262/340 [01:41<00:30,  2.56it/s]\u001b[A\n"," 77%|███████▋  | 263/340 [01:42<00:30,  2.56it/s]\u001b[A\n"," 78%|███████▊  | 264/340 [01:42<00:29,  2.55it/s]\u001b[A\n"," 78%|███████▊  | 265/340 [01:42<00:29,  2.54it/s]\u001b[A\n"," 78%|███████▊  | 266/340 [01:43<00:29,  2.54it/s]\u001b[A\n"," 79%|███████▊  | 267/340 [01:43<00:28,  2.53it/s]\u001b[A\n"," 79%|███████▉  | 268/340 [01:44<00:28,  2.53it/s]\u001b[A\n"," 79%|███████▉  | 269/340 [01:44<00:28,  2.53it/s]\u001b[A\n"," 79%|███████▉  | 270/340 [01:44<00:27,  2.54it/s]\u001b[A\n"," 80%|███████▉  | 271/340 [01:45<00:27,  2.53it/s]\u001b[A\n"," 80%|████████  | 272/340 [01:45<00:27,  2.50it/s]\u001b[A\n"," 80%|████████  | 273/340 [01:46<00:26,  2.54it/s]\u001b[A\n"," 81%|████████  | 274/340 [01:46<00:25,  2.54it/s]\u001b[A\n"," 81%|████████  | 275/340 [01:46<00:25,  2.55it/s]\u001b[A\n"," 81%|████████  | 276/340 [01:47<00:25,  2.55it/s]\u001b[A\n"," 81%|████████▏ | 277/340 [01:47<00:24,  2.54it/s]\u001b[A\n"," 82%|████████▏ | 278/340 [01:47<00:24,  2.55it/s]\u001b[A\n"," 82%|████████▏ | 279/340 [01:48<00:24,  2.54it/s]\u001b[A\n"," 82%|████████▏ | 280/340 [01:48<00:23,  2.55it/s]\u001b[A\n"," 83%|████████▎ | 281/340 [01:49<00:23,  2.54it/s]\u001b[A\n"," 83%|████████▎ | 282/340 [01:49<00:22,  2.53it/s]\u001b[A\n"," 83%|████████▎ | 283/340 [01:49<00:22,  2.53it/s]\u001b[A\n"," 84%|████████▎ | 284/340 [01:50<00:22,  2.54it/s]\u001b[A\n"," 84%|████████▍ | 285/340 [01:50<00:21,  2.54it/s]\u001b[A\n"," 84%|████████▍ | 286/340 [01:51<00:21,  2.54it/s]\u001b[A\n"," 84%|████████▍ | 287/340 [01:51<00:20,  2.54it/s]\u001b[A\n"," 85%|████████▍ | 288/340 [01:51<00:20,  2.54it/s]\u001b[A\n"," 85%|████████▌ | 289/340 [01:52<00:20,  2.54it/s]\u001b[A\n"," 85%|████████▌ | 290/340 [01:52<00:19,  2.54it/s]\u001b[A\n"," 86%|████████▌ | 291/340 [01:53<00:19,  2.55it/s]\u001b[A\n"," 86%|████████▌ | 292/340 [01:53<00:18,  2.54it/s]\u001b[A\n"," 86%|████████▌ | 293/340 [01:53<00:18,  2.53it/s]\u001b[A\n"," 86%|████████▋ | 294/340 [01:54<00:17,  2.56it/s]\u001b[A\n"," 87%|████████▋ | 295/340 [01:54<00:17,  2.55it/s]\u001b[A\n"," 87%|████████▋ | 296/340 [01:55<00:17,  2.55it/s]\u001b[A\n"," 87%|████████▋ | 297/340 [01:55<00:16,  2.54it/s]\u001b[A\n"," 88%|████████▊ | 298/340 [01:55<00:16,  2.54it/s]\u001b[A\n"," 88%|████████▊ | 299/340 [01:56<00:16,  2.55it/s]\u001b[A\n"," 88%|████████▊ | 300/340 [01:56<00:15,  2.57it/s]\u001b[A\n"," 89%|████████▊ | 301/340 [01:57<00:15,  2.56it/s]\u001b[A\n"," 89%|████████▉ | 302/340 [01:57<00:14,  2.55it/s]\u001b[A\n"," 89%|████████▉ | 303/340 [01:57<00:14,  2.54it/s]\u001b[A\n"," 89%|████████▉ | 304/340 [01:58<00:14,  2.55it/s]\u001b[A\n"," 90%|████████▉ | 305/340 [01:58<00:13,  2.56it/s]\u001b[A\n"," 90%|█████████ | 306/340 [01:58<00:13,  2.55it/s]\u001b[A\n"," 90%|█████████ | 307/340 [01:59<00:12,  2.55it/s]\u001b[A\n"," 91%|█████████ | 308/340 [01:59<00:12,  2.56it/s]\u001b[A\n"," 91%|█████████ | 309/340 [02:00<00:12,  2.55it/s]\u001b[A\n"," 91%|█████████ | 310/340 [02:00<00:11,  2.54it/s]\u001b[A\n"," 91%|█████████▏| 311/340 [02:00<00:11,  2.53it/s]\u001b[A\n"," 92%|█████████▏| 312/340 [02:01<00:11,  2.54it/s]\u001b[A\n"," 92%|█████████▏| 313/340 [02:01<00:10,  2.54it/s]\u001b[A\n"," 92%|█████████▏| 314/340 [02:02<00:10,  2.55it/s]\u001b[A\n"," 93%|█████████▎| 315/340 [02:02<00:09,  2.54it/s]\u001b[A\n"," 93%|█████████▎| 316/340 [02:02<00:09,  2.55it/s]\u001b[A\n"," 93%|█████████▎| 317/340 [02:03<00:09,  2.54it/s]\u001b[A\n"," 94%|█████████▎| 318/340 [02:03<00:08,  2.53it/s]\u001b[A\n"," 94%|█████████▍| 319/340 [02:04<00:08,  2.54it/s]\u001b[A\n"," 94%|█████████▍| 320/340 [02:04<00:07,  2.54it/s]\u001b[A\n"," 94%|█████████▍| 321/340 [02:04<00:07,  2.53it/s]\u001b[A\n"," 95%|█████████▍| 322/340 [02:05<00:07,  2.52it/s]\u001b[A\n"," 95%|█████████▌| 323/340 [02:05<00:06,  2.54it/s]\u001b[A\n"," 95%|█████████▌| 324/340 [02:06<00:06,  2.54it/s]\u001b[A\n"," 96%|█████████▌| 325/340 [02:06<00:05,  2.53it/s]\u001b[A\n"," 96%|█████████▌| 326/340 [02:06<00:05,  2.53it/s]\u001b[A\n"," 96%|█████████▌| 327/340 [02:07<00:05,  2.53it/s]\u001b[A\n"," 96%|█████████▋| 328/340 [02:07<00:04,  2.53it/s]\u001b[A\n"," 97%|█████████▋| 329/340 [02:08<00:04,  2.54it/s]\u001b[A\n"," 97%|█████████▋| 330/340 [02:08<00:03,  2.55it/s]\u001b[A\n"," 97%|█████████▋| 331/340 [02:08<00:03,  2.54it/s]\u001b[A\n"," 98%|█████████▊| 332/340 [02:09<00:03,  2.54it/s]\u001b[A\n"," 98%|█████████▊| 333/340 [02:09<00:02,  2.53it/s]\u001b[A\n"," 98%|█████████▊| 334/340 [02:10<00:02,  2.52it/s]\u001b[A\n"," 99%|█████████▊| 335/340 [02:10<00:01,  2.55it/s]\u001b[A\n"," 99%|█████████▉| 336/340 [02:10<00:01,  2.54it/s]\u001b[A\n"," 99%|█████████▉| 337/340 [02:11<00:01,  2.53it/s]\u001b[A\n"," 99%|█████████▉| 338/340 [02:11<00:00,  2.54it/s]\u001b[A\n","100%|█████████▉| 339/340 [02:11<00:00,  2.53it/s]\u001b[A\n","100%|██████████| 340/340 [02:12<00:00,  2.57it/s]\n"]},{"output_type":"stream","name":"stdout","text":["Epochs: 2 | Train Loss:  0.127             | Train Accuracy:  0.823             | Val Loss:  0.098             | Val Accuracy:  0.894\n"]},{"output_type":"stream","name":"stderr","text":["\n","  0%|          | 0/340 [00:00<?, ?it/s]\u001b[A\n","  0%|          | 1/340 [00:00<02:07,  2.65it/s]\u001b[A\n","  1%|          | 2/340 [00:00<02:11,  2.57it/s]\u001b[A\n","  1%|          | 3/340 [00:01<02:12,  2.55it/s]\u001b[A\n","  1%|          | 4/340 [00:01<02:11,  2.56it/s]\u001b[A\n","  1%|▏         | 5/340 [00:01<02:11,  2.55it/s]\u001b[A\n","  2%|▏         | 6/340 [00:02<02:12,  2.53it/s]\u001b[A\n","  2%|▏         | 7/340 [00:02<02:11,  2.53it/s]\u001b[A\n","  2%|▏         | 8/340 [00:03<02:10,  2.55it/s]\u001b[A\n","  3%|▎         | 9/340 [00:03<02:10,  2.54it/s]\u001b[A\n","  3%|▎         | 10/340 [00:03<02:09,  2.54it/s]\u001b[A\n","  3%|▎         | 11/340 [00:04<02:09,  2.53it/s]\u001b[A\n","  4%|▎         | 12/340 [00:04<02:09,  2.54it/s]\u001b[A\n","  4%|▍         | 13/340 [00:05<02:08,  2.55it/s]\u001b[A\n","  4%|▍         | 14/340 [00:05<02:08,  2.54it/s]\u001b[A\n","  4%|▍         | 15/340 [00:05<02:07,  2.54it/s]\u001b[A\n","  5%|▍         | 16/340 [00:06<02:07,  2.55it/s]\u001b[A\n","  5%|▌         | 17/340 [00:06<02:07,  2.53it/s]\u001b[A\n","  5%|▌         | 18/340 [00:07<02:07,  2.53it/s]\u001b[A\n","  6%|▌         | 19/340 [00:07<02:06,  2.53it/s]\u001b[A\n","  6%|▌         | 20/340 [00:07<02:06,  2.53it/s]\u001b[A\n","  6%|▌         | 21/340 [00:08<02:06,  2.53it/s]\u001b[A\n","  6%|▋         | 22/340 [00:08<02:05,  2.53it/s]\u001b[A\n","  7%|▋         | 23/340 [00:09<02:04,  2.55it/s]\u001b[A\n","  7%|▋         | 24/340 [00:09<02:04,  2.54it/s]\u001b[A\n","  7%|▋         | 25/340 [00:09<02:04,  2.53it/s]\u001b[A\n","  8%|▊         | 26/340 [00:10<02:04,  2.53it/s]\u001b[A\n","  8%|▊         | 27/340 [00:10<02:03,  2.52it/s]\u001b[A\n","  8%|▊         | 28/340 [00:11<02:03,  2.52it/s]\u001b[A\n","  9%|▊         | 29/340 [00:11<02:02,  2.53it/s]\u001b[A\n","  9%|▉         | 30/340 [00:11<02:03,  2.52it/s]\u001b[A\n","  9%|▉         | 31/340 [00:12<02:03,  2.51it/s]\u001b[A\n","  9%|▉         | 32/340 [00:12<02:02,  2.51it/s]\u001b[A\n"," 10%|▉         | 33/340 [00:13<02:02,  2.51it/s]\u001b[A\n"," 10%|█         | 34/340 [00:13<02:02,  2.51it/s]\u001b[A\n"," 10%|█         | 35/340 [00:13<02:00,  2.52it/s]\u001b[A\n"," 11%|█         | 36/340 [00:14<02:01,  2.51it/s]\u001b[A\n"," 11%|█         | 37/340 [00:14<01:59,  2.53it/s]\u001b[A\n"," 11%|█         | 38/340 [00:15<01:59,  2.54it/s]\u001b[A\n"," 11%|█▏        | 39/340 [00:15<01:58,  2.53it/s]\u001b[A\n"," 12%|█▏        | 40/340 [00:15<01:58,  2.53it/s]\u001b[A\n"," 12%|█▏        | 41/340 [00:16<01:58,  2.53it/s]\u001b[A\n"," 12%|█▏        | 42/340 [00:16<01:58,  2.52it/s]\u001b[A\n"," 13%|█▎        | 43/340 [00:16<01:57,  2.52it/s]\u001b[A\n"," 13%|█▎        | 44/340 [00:17<01:57,  2.52it/s]\u001b[A\n"," 13%|█▎        | 45/340 [00:17<01:57,  2.51it/s]\u001b[A\n"," 14%|█▎        | 46/340 [00:18<01:56,  2.52it/s]\u001b[A\n"," 14%|█▍        | 47/340 [00:18<01:56,  2.51it/s]\u001b[A\n"," 14%|█▍        | 48/340 [00:18<01:56,  2.51it/s]\u001b[A\n"," 14%|█▍        | 49/340 [00:19<01:55,  2.52it/s]\u001b[A\n"," 15%|█▍        | 50/340 [00:19<01:54,  2.53it/s]\u001b[A\n"," 15%|█▌        | 51/340 [00:20<01:53,  2.54it/s]\u001b[A\n"," 15%|█▌        | 52/340 [00:20<01:53,  2.53it/s]\u001b[A\n"," 16%|█▌        | 53/340 [00:20<01:53,  2.52it/s]\u001b[A\n"," 16%|█▌        | 54/340 [00:21<01:52,  2.53it/s]\u001b[A\n"," 16%|█▌        | 55/340 [00:21<01:52,  2.53it/s]\u001b[A\n"," 16%|█▋        | 56/340 [00:22<01:52,  2.52it/s]\u001b[A\n"," 17%|█▋        | 57/340 [00:22<01:52,  2.52it/s]\u001b[A\n"," 17%|█▋        | 58/340 [00:22<01:51,  2.53it/s]\u001b[A\n"," 17%|█▋        | 59/340 [00:23<01:51,  2.53it/s]\u001b[A\n"," 18%|█▊        | 60/340 [00:23<01:51,  2.50it/s]\u001b[A\n"," 18%|█▊        | 61/340 [00:24<01:52,  2.49it/s]\u001b[A\n"," 18%|█▊        | 62/340 [00:24<01:51,  2.49it/s]\u001b[A\n"," 19%|█▊        | 63/340 [00:24<01:51,  2.49it/s]\u001b[A\n"," 19%|█▉        | 64/340 [00:25<01:51,  2.47it/s]\u001b[A\n"," 19%|█▉        | 65/340 [00:25<01:51,  2.48it/s]\u001b[A\n"," 19%|█▉        | 66/340 [00:26<01:49,  2.49it/s]\u001b[A\n"," 20%|█▉        | 67/340 [00:26<01:50,  2.47it/s]\u001b[A\n"," 20%|██        | 68/340 [00:26<01:49,  2.49it/s]\u001b[A\n"," 20%|██        | 69/340 [00:27<01:48,  2.50it/s]\u001b[A\n"," 21%|██        | 70/340 [00:27<01:48,  2.49it/s]\u001b[A\n"," 21%|██        | 71/340 [00:28<01:47,  2.50it/s]\u001b[A\n"," 21%|██        | 72/340 [00:28<01:47,  2.50it/s]\u001b[A\n"," 21%|██▏       | 73/340 [00:28<01:46,  2.50it/s]\u001b[A\n"," 22%|██▏       | 74/340 [00:29<01:46,  2.50it/s]\u001b[A\n"," 22%|██▏       | 75/340 [00:29<01:46,  2.50it/s]\u001b[A\n"," 22%|██▏       | 76/340 [00:30<01:45,  2.51it/s]\u001b[A\n"," 23%|██▎       | 77/340 [00:30<01:44,  2.51it/s]\u001b[A\n"," 23%|██▎       | 78/340 [00:30<01:44,  2.52it/s]\u001b[A\n"," 23%|██▎       | 79/340 [00:31<01:43,  2.52it/s]\u001b[A\n"," 24%|██▎       | 80/340 [00:31<01:43,  2.51it/s]\u001b[A\n"," 24%|██▍       | 81/340 [00:32<01:44,  2.48it/s]\u001b[A\n"," 24%|██▍       | 82/340 [00:32<01:43,  2.50it/s]\u001b[A\n"," 24%|██▍       | 83/340 [00:32<01:42,  2.51it/s]\u001b[A\n"," 25%|██▍       | 84/340 [00:33<01:42,  2.51it/s]\u001b[A\n"," 25%|██▌       | 85/340 [00:33<01:41,  2.52it/s]\u001b[A\n"," 25%|██▌       | 86/340 [00:34<01:40,  2.52it/s]\u001b[A\n"," 26%|██▌       | 87/340 [00:34<01:40,  2.52it/s]\u001b[A\n"," 26%|██▌       | 88/340 [00:34<01:39,  2.53it/s]\u001b[A\n"," 26%|██▌       | 89/340 [00:35<01:38,  2.54it/s]\u001b[A\n"," 26%|██▋       | 90/340 [00:35<01:38,  2.54it/s]\u001b[A\n"," 27%|██▋       | 91/340 [00:36<01:38,  2.53it/s]\u001b[A\n"," 27%|██▋       | 92/340 [00:36<01:38,  2.53it/s]\u001b[A\n"," 27%|██▋       | 93/340 [00:36<01:38,  2.52it/s]\u001b[A\n"," 28%|██▊       | 94/340 [00:37<01:37,  2.52it/s]\u001b[A\n"," 28%|██▊       | 95/340 [00:37<01:37,  2.51it/s]\u001b[A\n"," 28%|██▊       | 96/340 [00:38<01:36,  2.52it/s]\u001b[A\n"," 29%|██▊       | 97/340 [00:38<01:36,  2.52it/s]\u001b[A\n"," 29%|██▉       | 98/340 [00:38<01:35,  2.53it/s]\u001b[A\n"," 29%|██▉       | 99/340 [00:39<01:34,  2.55it/s]\u001b[A\n"," 29%|██▉       | 100/340 [00:39<01:34,  2.54it/s]\u001b[A\n"," 30%|██▉       | 101/340 [00:40<01:34,  2.54it/s]\u001b[A\n"," 30%|███       | 102/340 [00:40<01:33,  2.55it/s]\u001b[A\n"," 30%|███       | 103/340 [00:40<01:33,  2.54it/s]\u001b[A\n"," 31%|███       | 104/340 [00:41<01:33,  2.53it/s]\u001b[A\n"," 31%|███       | 105/340 [00:41<01:32,  2.53it/s]\u001b[A\n"," 31%|███       | 106/340 [00:42<01:32,  2.52it/s]\u001b[A\n"," 31%|███▏      | 107/340 [00:42<01:31,  2.53it/s]\u001b[A\n"," 32%|███▏      | 108/340 [00:42<01:31,  2.53it/s]\u001b[A\n"," 32%|███▏      | 109/340 [00:43<01:31,  2.52it/s]\u001b[A\n"," 32%|███▏      | 110/340 [00:43<01:31,  2.53it/s]\u001b[A\n"," 33%|███▎      | 111/340 [00:44<01:30,  2.53it/s]\u001b[A\n"," 33%|███▎      | 112/340 [00:44<01:30,  2.52it/s]\u001b[A\n"," 33%|███▎      | 113/340 [00:44<01:30,  2.52it/s]\u001b[A\n"," 34%|███▎      | 114/340 [00:45<01:29,  2.53it/s]\u001b[A\n"," 34%|███▍      | 115/340 [00:45<01:28,  2.54it/s]\u001b[A\n"," 34%|███▍      | 116/340 [00:45<01:28,  2.54it/s]\u001b[A\n"," 34%|███▍      | 117/340 [00:46<01:27,  2.56it/s]\u001b[A\n"," 35%|███▍      | 118/340 [00:46<01:26,  2.56it/s]\u001b[A\n"," 35%|███▌      | 119/340 [00:47<01:26,  2.55it/s]\u001b[A\n"," 35%|███▌      | 120/340 [00:47<01:26,  2.55it/s]\u001b[A\n"," 36%|███▌      | 121/340 [00:47<01:26,  2.54it/s]\u001b[A\n"," 36%|███▌      | 122/340 [00:48<01:25,  2.54it/s]\u001b[A\n"," 36%|███▌      | 123/340 [00:48<01:25,  2.53it/s]\u001b[A\n"," 36%|███▋      | 124/340 [00:49<01:25,  2.52it/s]\u001b[A\n"," 37%|███▋      | 125/340 [00:49<01:24,  2.53it/s]\u001b[A\n"," 37%|███▋      | 126/340 [00:49<01:24,  2.53it/s]\u001b[A\n"," 37%|███▋      | 127/340 [00:50<01:24,  2.52it/s]\u001b[A\n"," 38%|███▊      | 128/340 [00:50<01:23,  2.53it/s]\u001b[A\n"," 38%|███▊      | 129/340 [00:51<01:23,  2.52it/s]\u001b[A\n"," 38%|███▊      | 130/340 [00:51<01:23,  2.51it/s]\u001b[A\n"," 39%|███▊      | 131/340 [00:51<01:23,  2.50it/s]\u001b[A\n"," 39%|███▉      | 132/340 [00:52<01:22,  2.51it/s]\u001b[A\n"," 39%|███▉      | 133/340 [00:52<01:22,  2.51it/s]\u001b[A\n"," 39%|███▉      | 134/340 [00:53<01:21,  2.52it/s]\u001b[A\n"," 40%|███▉      | 135/340 [00:53<01:21,  2.52it/s]\u001b[A\n"," 40%|████      | 136/340 [00:53<01:21,  2.51it/s]\u001b[A\n"," 40%|████      | 137/340 [00:54<01:20,  2.53it/s]\u001b[A\n"," 41%|████      | 138/340 [00:54<01:19,  2.53it/s]\u001b[A\n"," 41%|████      | 139/340 [00:55<01:19,  2.53it/s]\u001b[A\n"," 41%|████      | 140/340 [00:55<01:19,  2.52it/s]\u001b[A\n"," 41%|████▏     | 141/340 [00:55<01:19,  2.52it/s]\u001b[A\n"," 42%|████▏     | 142/340 [00:56<01:18,  2.52it/s]\u001b[A\n"," 42%|████▏     | 143/340 [00:56<01:18,  2.53it/s]\u001b[A\n"," 42%|████▏     | 144/340 [00:57<01:17,  2.53it/s]\u001b[A\n"," 43%|████▎     | 145/340 [00:57<01:17,  2.52it/s]\u001b[A\n"," 43%|████▎     | 146/340 [00:57<01:17,  2.52it/s]\u001b[A\n"," 43%|████▎     | 147/340 [00:58<01:16,  2.52it/s]\u001b[A\n"," 44%|████▎     | 148/340 [00:58<01:16,  2.52it/s]\u001b[A\n"," 44%|████▍     | 149/340 [00:59<01:15,  2.53it/s]\u001b[A\n"," 44%|████▍     | 150/340 [00:59<01:15,  2.52it/s]\u001b[A\n"," 44%|████▍     | 151/340 [00:59<01:14,  2.53it/s]\u001b[A\n"," 45%|████▍     | 152/340 [01:00<01:14,  2.53it/s]\u001b[A\n"," 45%|████▌     | 153/340 [01:00<01:13,  2.53it/s]\u001b[A\n"," 45%|████▌     | 154/340 [01:01<01:13,  2.54it/s]\u001b[A\n"," 46%|████▌     | 155/340 [01:01<01:12,  2.54it/s]\u001b[A\n"," 46%|████▌     | 156/340 [01:01<01:12,  2.54it/s]\u001b[A\n"," 46%|████▌     | 157/340 [01:02<01:11,  2.55it/s]\u001b[A\n"," 46%|████▋     | 158/340 [01:02<01:11,  2.54it/s]\u001b[A\n"," 47%|████▋     | 159/340 [01:03<01:11,  2.53it/s]\u001b[A\n"," 47%|████▋     | 160/340 [01:03<01:11,  2.52it/s]\u001b[A\n"," 47%|████▋     | 161/340 [01:03<01:11,  2.51it/s]\u001b[A\n"," 48%|████▊     | 162/340 [01:04<01:10,  2.53it/s]\u001b[A\n"," 48%|████▊     | 163/340 [01:04<01:10,  2.52it/s]\u001b[A\n"," 48%|████▊     | 164/340 [01:04<01:09,  2.55it/s]\u001b[A\n"," 49%|████▊     | 165/340 [01:05<01:09,  2.54it/s]\u001b[A\n"," 49%|████▉     | 166/340 [01:05<01:08,  2.54it/s]\u001b[A\n"," 49%|████▉     | 167/340 [01:06<01:08,  2.53it/s]\u001b[A\n"," 49%|████▉     | 168/340 [01:06<01:07,  2.54it/s]\u001b[A\n"," 50%|████▉     | 169/340 [01:06<01:07,  2.52it/s]\u001b[A\n"," 50%|█████     | 170/340 [01:07<01:06,  2.54it/s]\u001b[A\n"," 50%|█████     | 171/340 [01:07<01:06,  2.55it/s]\u001b[A\n"," 51%|█████     | 172/340 [01:08<01:06,  2.53it/s]\u001b[A\n"," 51%|█████     | 173/340 [01:08<01:05,  2.53it/s]\u001b[A\n"," 51%|█████     | 174/340 [01:08<01:05,  2.54it/s]\u001b[A\n"," 51%|█████▏    | 175/340 [01:09<01:05,  2.52it/s]\u001b[A\n"," 52%|█████▏    | 176/340 [01:09<01:05,  2.51it/s]\u001b[A\n"," 52%|█████▏    | 177/340 [01:10<01:03,  2.57it/s]\u001b[A\n"," 52%|█████▏    | 178/340 [01:10<01:03,  2.55it/s]\u001b[A\n"," 53%|█████▎    | 179/340 [01:10<01:03,  2.54it/s]\u001b[A\n"," 53%|█████▎    | 180/340 [01:11<01:02,  2.56it/s]\u001b[A\n"," 53%|█████▎    | 181/340 [01:11<01:02,  2.55it/s]\u001b[A\n"," 54%|█████▎    | 182/340 [01:12<01:02,  2.53it/s]\u001b[A\n"," 54%|█████▍    | 183/340 [01:12<01:01,  2.54it/s]\u001b[A\n"," 54%|█████▍    | 184/340 [01:12<01:01,  2.54it/s]\u001b[A\n"," 54%|█████▍    | 185/340 [01:13<01:01,  2.53it/s]\u001b[A\n"," 55%|█████▍    | 186/340 [01:13<01:00,  2.53it/s]\u001b[A\n"," 55%|█████▌    | 187/340 [01:14<01:00,  2.54it/s]\u001b[A\n"," 55%|█████▌    | 188/340 [01:14<01:00,  2.53it/s]\u001b[A\n"," 56%|█████▌    | 189/340 [01:14<00:59,  2.52it/s]\u001b[A\n"," 56%|█████▌    | 190/340 [01:15<00:58,  2.54it/s]\u001b[A\n"," 56%|█████▌    | 191/340 [01:15<00:58,  2.55it/s]\u001b[A\n"," 56%|█████▋    | 192/340 [01:16<00:58,  2.53it/s]\u001b[A\n"," 57%|█████▋    | 193/340 [01:16<00:57,  2.55it/s]\u001b[A\n"," 57%|█████▋    | 194/340 [01:16<00:57,  2.53it/s]\u001b[A\n"," 57%|█████▋    | 195/340 [01:17<00:57,  2.53it/s]\u001b[A\n"," 58%|█████▊    | 196/340 [01:17<00:56,  2.54it/s]\u001b[A\n"," 58%|█████▊    | 197/340 [01:17<00:56,  2.53it/s]\u001b[A\n"," 58%|█████▊    | 198/340 [01:18<00:56,  2.53it/s]\u001b[A\n"," 59%|█████▊    | 199/340 [01:18<00:55,  2.54it/s]\u001b[A\n"," 59%|█████▉    | 200/340 [01:19<00:55,  2.53it/s]\u001b[A\n"," 59%|█████▉    | 201/340 [01:19<00:54,  2.54it/s]\u001b[A\n"," 59%|█████▉    | 202/340 [01:19<00:54,  2.53it/s]\u001b[A\n"," 60%|█████▉    | 203/340 [01:20<00:54,  2.53it/s]\u001b[A\n"," 60%|██████    | 204/340 [01:20<00:53,  2.54it/s]\u001b[A\n"," 60%|██████    | 205/340 [01:21<00:53,  2.52it/s]\u001b[A\n"," 61%|██████    | 206/340 [01:21<00:53,  2.52it/s]\u001b[A\n"," 61%|██████    | 207/340 [01:21<00:52,  2.52it/s]\u001b[A\n"," 61%|██████    | 208/340 [01:22<00:52,  2.53it/s]\u001b[A\n"," 61%|██████▏   | 209/340 [01:22<00:51,  2.52it/s]\u001b[A\n"," 62%|██████▏   | 210/340 [01:23<00:51,  2.53it/s]\u001b[A\n"," 62%|██████▏   | 211/340 [01:23<00:51,  2.52it/s]\u001b[A\n"," 62%|██████▏   | 212/340 [01:23<00:50,  2.54it/s]\u001b[A\n"," 63%|██████▎   | 213/340 [01:24<00:50,  2.54it/s]\u001b[A\n"," 63%|██████▎   | 214/340 [01:24<00:49,  2.54it/s]\u001b[A\n"," 63%|██████▎   | 215/340 [01:25<00:49,  2.53it/s]\u001b[A\n"," 64%|██████▎   | 216/340 [01:25<00:49,  2.52it/s]\u001b[A\n"," 64%|██████▍   | 217/340 [01:25<00:48,  2.52it/s]\u001b[A\n"," 64%|██████▍   | 218/340 [01:26<00:48,  2.52it/s]\u001b[A\n"," 64%|██████▍   | 219/340 [01:26<00:47,  2.53it/s]\u001b[A\n"," 65%|██████▍   | 220/340 [01:27<00:47,  2.52it/s]\u001b[A\n"," 65%|██████▌   | 221/340 [01:27<00:47,  2.52it/s]\u001b[A\n"," 65%|██████▌   | 222/340 [01:27<00:46,  2.52it/s]\u001b[A\n"," 66%|██████▌   | 223/340 [01:28<00:46,  2.52it/s]\u001b[A\n"," 66%|██████▌   | 224/340 [01:28<00:46,  2.51it/s]\u001b[A\n"," 66%|██████▌   | 225/340 [01:29<00:45,  2.51it/s]\u001b[A\n"," 66%|██████▋   | 226/340 [01:29<00:45,  2.53it/s]\u001b[A\n"," 67%|██████▋   | 227/340 [01:29<00:44,  2.52it/s]\u001b[A\n"," 67%|██████▋   | 228/340 [01:30<00:44,  2.53it/s]\u001b[A\n"," 67%|██████▋   | 229/340 [01:30<00:43,  2.52it/s]\u001b[A\n"," 68%|██████▊   | 230/340 [01:31<00:43,  2.55it/s]\u001b[A\n"," 68%|██████▊   | 231/340 [01:31<00:42,  2.55it/s]\u001b[A\n"," 68%|██████▊   | 232/340 [01:31<00:42,  2.54it/s]\u001b[A\n"," 69%|██████▊   | 233/340 [01:32<00:41,  2.55it/s]\u001b[A\n"," 69%|██████▉   | 234/340 [01:32<00:41,  2.55it/s]\u001b[A\n"," 69%|██████▉   | 235/340 [01:33<00:41,  2.54it/s]\u001b[A\n"," 69%|██████▉   | 236/340 [01:33<00:40,  2.54it/s]\u001b[A\n"," 70%|██████▉   | 237/340 [01:33<00:40,  2.53it/s]\u001b[A\n"," 70%|███████   | 238/340 [01:34<00:40,  2.55it/s]\u001b[A\n"," 70%|███████   | 239/340 [01:34<00:39,  2.53it/s]\u001b[A\n"," 71%|███████   | 240/340 [01:34<00:39,  2.53it/s]\u001b[A\n"," 71%|███████   | 241/340 [01:35<00:38,  2.54it/s]\u001b[A\n"," 71%|███████   | 242/340 [01:35<00:38,  2.53it/s]\u001b[A\n"," 71%|███████▏  | 243/340 [01:36<00:38,  2.53it/s]\u001b[A\n"," 72%|███████▏  | 244/340 [01:36<00:37,  2.53it/s]\u001b[A\n"," 72%|███████▏  | 245/340 [01:36<00:37,  2.53it/s]\u001b[A\n"," 72%|███████▏  | 246/340 [01:37<00:36,  2.54it/s]\u001b[A\n"," 73%|███████▎  | 247/340 [01:37<00:36,  2.56it/s]\u001b[A\n"," 73%|███████▎  | 248/340 [01:38<00:35,  2.57it/s]\u001b[A\n"," 73%|███████▎  | 249/340 [01:38<00:35,  2.55it/s]\u001b[A\n"," 74%|███████▎  | 250/340 [01:38<00:35,  2.54it/s]\u001b[A\n"," 74%|███████▍  | 251/340 [01:39<00:35,  2.53it/s]\u001b[A\n"," 74%|███████▍  | 252/340 [01:39<00:34,  2.53it/s]\u001b[A\n"," 74%|███████▍  | 253/340 [01:40<00:34,  2.53it/s]\u001b[A\n"," 75%|███████▍  | 254/340 [01:40<00:34,  2.52it/s]\u001b[A\n"," 75%|███████▌  | 255/340 [01:40<00:33,  2.53it/s]\u001b[A\n"," 75%|███████▌  | 256/340 [01:41<00:33,  2.53it/s]\u001b[A\n"," 76%|███████▌  | 257/340 [01:41<00:32,  2.55it/s]\u001b[A\n"," 76%|███████▌  | 258/340 [01:42<00:32,  2.55it/s]\u001b[A\n"," 76%|███████▌  | 259/340 [01:42<00:31,  2.53it/s]\u001b[A\n"," 76%|███████▋  | 260/340 [01:42<00:31,  2.53it/s]\u001b[A\n"," 77%|███████▋  | 261/340 [01:43<00:31,  2.54it/s]\u001b[A\n"," 77%|███████▋  | 262/340 [01:43<00:30,  2.54it/s]\u001b[A\n"," 77%|███████▋  | 263/340 [01:44<00:30,  2.55it/s]\u001b[A\n"," 78%|███████▊  | 264/340 [01:44<00:29,  2.53it/s]\u001b[A\n"," 78%|███████▊  | 265/340 [01:44<00:29,  2.53it/s]\u001b[A\n"," 78%|███████▊  | 266/340 [01:45<00:29,  2.54it/s]\u001b[A\n"," 79%|███████▊  | 267/340 [01:45<00:28,  2.55it/s]\u001b[A\n"," 79%|███████▉  | 268/340 [01:46<00:28,  2.55it/s]\u001b[A\n"," 79%|███████▉  | 269/340 [01:46<00:27,  2.55it/s]\u001b[A\n"," 79%|███████▉  | 270/340 [01:46<00:27,  2.54it/s]\u001b[A\n"," 80%|███████▉  | 271/340 [01:47<00:27,  2.55it/s]\u001b[A\n"," 80%|████████  | 272/340 [01:47<00:26,  2.54it/s]\u001b[A\n"," 80%|████████  | 273/340 [01:47<00:26,  2.52it/s]\u001b[A\n"," 81%|████████  | 274/340 [01:48<00:25,  2.54it/s]\u001b[A\n"," 81%|████████  | 275/340 [01:48<00:25,  2.53it/s]\u001b[A\n"," 81%|████████  | 276/340 [01:49<00:25,  2.55it/s]\u001b[A\n"," 81%|████████▏ | 277/340 [01:49<00:24,  2.54it/s]\u001b[A\n"," 82%|████████▏ | 278/340 [01:49<00:24,  2.54it/s]\u001b[A\n"," 82%|████████▏ | 279/340 [01:50<00:23,  2.54it/s]\u001b[A\n"," 82%|████████▏ | 280/340 [01:50<00:23,  2.54it/s]\u001b[A\n"," 83%|████████▎ | 281/340 [01:51<00:23,  2.53it/s]\u001b[A\n"," 83%|████████▎ | 282/340 [01:51<00:22,  2.53it/s]\u001b[A\n"," 83%|████████▎ | 283/340 [01:51<00:22,  2.52it/s]\u001b[A\n"," 84%|████████▎ | 284/340 [01:52<00:22,  2.52it/s]\u001b[A\n"," 84%|████████▍ | 285/340 [01:52<00:21,  2.52it/s]\u001b[A\n"," 84%|████████▍ | 286/340 [01:53<00:21,  2.51it/s]\u001b[A\n"," 84%|████████▍ | 287/340 [01:53<00:21,  2.52it/s]\u001b[A\n"," 85%|████████▍ | 288/340 [01:53<00:20,  2.53it/s]\u001b[A\n"," 85%|████████▌ | 289/340 [01:54<00:20,  2.53it/s]\u001b[A\n"," 85%|████████▌ | 290/340 [01:54<00:19,  2.53it/s]\u001b[A\n"," 86%|████████▌ | 291/340 [01:55<00:19,  2.52it/s]\u001b[A\n"," 86%|████████▌ | 292/340 [01:55<00:18,  2.53it/s]\u001b[A\n"," 86%|████████▌ | 293/340 [01:55<00:18,  2.53it/s]\u001b[A\n"," 86%|████████▋ | 294/340 [01:56<00:18,  2.54it/s]\u001b[A\n"," 87%|████████▋ | 295/340 [01:56<00:18,  2.50it/s]\u001b[A\n"," 87%|████████▋ | 296/340 [01:57<00:17,  2.51it/s]\u001b[A\n"," 87%|████████▋ | 297/340 [01:57<00:17,  2.50it/s]\u001b[A\n"," 88%|████████▊ | 298/340 [01:57<00:16,  2.51it/s]\u001b[A\n"," 88%|████████▊ | 299/340 [01:58<00:16,  2.52it/s]\u001b[A\n"," 88%|████████▊ | 300/340 [01:58<00:16,  2.49it/s]\u001b[A\n"," 89%|████████▊ | 301/340 [01:59<00:15,  2.49it/s]\u001b[A\n"," 89%|████████▉ | 302/340 [01:59<00:15,  2.48it/s]\u001b[A\n"," 89%|████████▉ | 303/340 [01:59<00:14,  2.49it/s]\u001b[A\n"," 89%|████████▉ | 304/340 [02:00<00:14,  2.49it/s]\u001b[A\n"," 90%|████████▉ | 305/340 [02:00<00:13,  2.52it/s]\u001b[A\n"," 90%|█████████ | 306/340 [02:01<00:13,  2.51it/s]\u001b[A\n"," 90%|█████████ | 307/340 [02:01<00:13,  2.51it/s]\u001b[A\n"," 91%|█████████ | 308/340 [02:01<00:12,  2.53it/s]\u001b[A\n"," 91%|█████████ | 309/340 [02:02<00:12,  2.52it/s]\u001b[A\n"," 91%|█████████ | 310/340 [02:02<00:11,  2.52it/s]\u001b[A\n"," 91%|█████████▏| 311/340 [02:03<00:11,  2.52it/s]\u001b[A\n"," 92%|█████████▏| 312/340 [02:03<00:11,  2.52it/s]\u001b[A\n"," 92%|█████████▏| 313/340 [02:03<00:10,  2.53it/s]\u001b[A\n"," 92%|█████████▏| 314/340 [02:04<00:10,  2.52it/s]\u001b[A\n"," 93%|█████████▎| 315/340 [02:04<00:09,  2.53it/s]\u001b[A\n"," 93%|█████████▎| 316/340 [02:05<00:09,  2.52it/s]\u001b[A\n"," 93%|█████████▎| 317/340 [02:05<00:09,  2.52it/s]\u001b[A\n"," 94%|█████████▎| 318/340 [02:05<00:08,  2.51it/s]\u001b[A\n"," 94%|█████████▍| 319/340 [02:06<00:08,  2.51it/s]\u001b[A\n"," 94%|█████████▍| 320/340 [02:06<00:07,  2.51it/s]\u001b[A\n"," 94%|█████████▍| 321/340 [02:07<00:07,  2.52it/s]\u001b[A\n"," 95%|█████████▍| 322/340 [02:07<00:07,  2.52it/s]\u001b[A\n"," 95%|█████████▌| 323/340 [02:07<00:06,  2.52it/s]\u001b[A\n"," 95%|█████████▌| 324/340 [02:08<00:06,  2.53it/s]\u001b[A\n"," 96%|█████████▌| 325/340 [02:08<00:05,  2.52it/s]\u001b[A\n"," 96%|█████████▌| 326/340 [02:09<00:05,  2.51it/s]\u001b[A\n"," 96%|█████████▌| 327/340 [02:09<00:05,  2.51it/s]\u001b[A\n"," 96%|█████████▋| 328/340 [02:09<00:04,  2.52it/s]\u001b[A\n"," 97%|█████████▋| 329/340 [02:10<00:04,  2.52it/s]\u001b[A\n"," 97%|█████████▋| 330/340 [02:10<00:03,  2.53it/s]\u001b[A\n"," 97%|█████████▋| 331/340 [02:11<00:03,  2.52it/s]\u001b[A\n"," 98%|█████████▊| 332/340 [02:11<00:03,  2.54it/s]\u001b[A\n"," 98%|█████████▊| 333/340 [02:11<00:02,  2.55it/s]\u001b[A\n"," 98%|█████████▊| 334/340 [02:12<00:02,  2.52it/s]\u001b[A\n"," 99%|█████████▊| 335/340 [02:12<00:01,  2.54it/s]\u001b[A\n"," 99%|█████████▉| 336/340 [02:12<00:01,  2.53it/s]\u001b[A\n"," 99%|█████████▉| 337/340 [02:13<00:01,  2.54it/s]\u001b[A\n"," 99%|█████████▉| 338/340 [02:13<00:00,  2.55it/s]\u001b[A\n","100%|█████████▉| 339/340 [02:14<00:00,  2.55it/s]\u001b[A\n","100%|██████████| 340/340 [02:14<00:00,  2.53it/s]\n"]},{"output_type":"stream","name":"stdout","text":["Epochs: 3 | Train Loss:  0.058             | Train Accuracy:  0.935             | Val Loss:  0.083             | Val Accuracy:  0.912\n"]},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.Javascript object>"],"application/javascript":["\n","    async function download(id, filename, size) {\n","      if (!google.colab.kernel.accessAllowed) {\n","        return;\n","      }\n","      const div = document.createElement('div');\n","      const label = document.createElement('label');\n","      label.textContent = `Downloading \"${filename}\": `;\n","      div.appendChild(label);\n","      const progress = document.createElement('progress');\n","      progress.max = size;\n","      div.appendChild(progress);\n","      document.body.appendChild(div);\n","\n","      const buffers = [];\n","      let downloaded = 0;\n","\n","      const channel = await google.colab.kernel.comms.open(id);\n","      // Send a message to notify the kernel that we're ready.\n","      channel.send({})\n","\n","      for await (const message of channel.messages) {\n","        // Send a message to notify the kernel that we're ready.\n","        channel.send({})\n","        if (message.buffers) {\n","          for (const buffer of message.buffers) {\n","            buffers.push(buffer);\n","            downloaded += buffer.byteLength;\n","            progress.value = downloaded;\n","          }\n","        }\n","      }\n","      const blob = new Blob(buffers, {type: 'application/binary'});\n","      const a = document.createElement('a');\n","      a.href = window.URL.createObjectURL(blob);\n","      a.download = filename;\n","      div.appendChild(a);\n","      a.click();\n","      div.remove();\n","    }\n","  "]},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.Javascript object>"],"application/javascript":["download(\"download_bc052f5d-f3dd-4dce-933a-de13b5cff84d\", \"checkpoint_tuned.pth\", 433722025)"]},"metadata":{}}],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":1000,"referenced_widgets":["8ced2d7a699d44a5b85d76aee4928b15","98481ee5c9a040c18bd7854791d466bf","e07c295cc1af468f8f81f4c388185c50","0a5940163ae24c4f80499ceb84a576b3","7b28bdb4d9644d2da5e56cf13f631d12","6392bf64751d4793a35aa1091ed27220","4396c764d64b4f95a10a61ecabe742b9","8dad15a4caaa40f69b7fddcf878febc5","4d5a7d56ee5a4da8b5e17b465b0da251","054a160162a744809f5d392f00baa9eb","42cc0c1c3b4449c2ba7cfa9ef12837a3","2ee4c9d79ed14932a61ef9ab43a7a7c8","6a696060459d4eecb7e2cbb9c5e333ca","bf0bb65a42f54787b81aa50761b98795","9c562cdd90be4ed28ce706f5afb184c3","6f14feb53e154d67a68b3ed1fc7b63b9","dfbab0ca2549498f97f762cdb1f52c50","667808f5ef7f4d4bbaa97cec63044955","08caf25f85e1404d805efcb9ed3e5efc","ec0f7d1a6e3e4a3785379f394848e23c","2456e9405e7c40c8a5bf5f42f47ef82a","b2832c5b6dac4d66a52c5fb0e046aaf3"]},"id":"PHczxNZKOR-S","executionInfo":{"status":"ok","timestamp":1648564461400,"user_tz":240,"elapsed":448736,"user":{"displayName":"Vruthik Thakkar","userId":"03035406201152502707"}},"outputId":"a054ff27-8bd4-4a3a-d9b1-2563b0f44867"}},{"cell_type":"markdown","source":["# Test Model"],"metadata":{"id":"eHfbh04HM5oz"}},{"cell_type":"code","execution_count":19,"source":["from model import Dataset\n","from eval import Evaluation\n","\n","use_cuda = torch.cuda.is_available()\n","device = torch.device(\"cuda\" if use_cuda else \"cpu\")\n","\n","model_test = BertClassifier(hidden_size=hidden_size)\n","state_dict = torch.load(os.path.join(GOOGLE_DRIVE_PATH, 'checkpoint_tuned.pth'))\n","model_test.load_state_dict(state_dict)\n","model_test.to(device)\n","\n","test_data = Dataset(df_test)\n","test_dataloader = torch.utils.data.DataLoader(test_data, batch_size=batch_size, shuffle=True)\n","\n","use_cuda = torch.cuda.is_available()\n","device = torch.device(\"cuda\" if use_cuda else \"cpu\")\n","\n","total_acc_test = 0\n","with torch.no_grad():\n","    preds = []\n","    labels = []\n","    for test_input, test_label in tqdm(test_dataloader):\n","        test_label = test_label.to(device)\n","        mask = test_input['attention_mask'].to(device)\n","        input_id = test_input['input_ids'].squeeze(1).to(device)\n","\n","        output = model_test(input_id, mask)\n","        acc = (output.argmax(dim=1) == test_label).sum().item()\n","        preds.extend(output.argmax(dim=1).tolist())\n","        labels.extend(test_label.tolist())\n","        total_acc_test += acc\n","\n","eval = Evaluation(preds, labels)\n","eval.all_metrics()\n"],"outputs":[{"output_type":"stream","name":"stderr","text":["Some weights of the model checkpoint at bert-base-cased were not used when initializing BertModel: ['cls.predictions.decoder.weight', 'cls.seq_relationship.weight', 'cls.seq_relationship.bias', 'cls.predictions.bias', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.transform.dense.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.dense.weight']\n","- This IS expected if you are initializing BertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n","- This IS NOT expected if you are initializing BertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n","100%|██████████| 43/43 [00:05<00:00,  8.02it/s]\n"]},{"output_type":"stream","name":"stdout","text":["Accuracy: 0.9058823529411765\n","-----------------------\n","Macro\n","F1 score macro: 0.91614417989418\n","Precision macro: 0.9156813063063063\n","Recall macro: 0.9168612054329373\n","-----------------------\n","Micro\n","F1 score micro: 0.9058823529411765\n","Precision micro: 0.9058823529411765\n","Recall micro: 0.9058823529411765\n"]}],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"_hETnBKlry6b","executionInfo":{"status":"ok","timestamp":1648564727651,"user_tz":240,"elapsed":12385,"user":{"displayName":"Vruthik Thakkar","userId":"03035406201152502707"}},"outputId":"16ad076f-b3b9-4d9d-dad7-5a463b6b4a22"}}]}